{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to evaluate a set of metadata categories to identify factors which may be interesting to pursue further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import skbio\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from skbio.stats.power import subsample_power, confidence_bound\n",
    "\n",
    "from americangut.ag_data_dictionary import *\n",
    "from americangut.ag_data import AgData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's select a dataset to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bodysite = 'fecal'\n",
    "sequence_trim = '100nt'\n",
    "rarefaction_depth = '10k'\n",
    "\n",
    "use_subset = False\n",
    "use_one_sample = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's select a list of groups to interogate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fecal_data = AgData(bodysite=bodysite, \n",
    "                    trim=sequence_trim, \n",
    "                    depth=rarefaction_depth, \n",
    "                    sub_participants=use_subset, \n",
    "                    one_sample=use_one_sample)\n",
    "fecal_data.drop_alpha_outliers()\n",
    "\n",
    "\n",
    "fecal_data.drop_bmi_outliers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def _remap_abx(x):\n",
    "    if x == 'I have not taken antibiotics in the past year':\n",
    "        return 'More than 1 year'\n",
    "def _remap_bowel_frequency(x):\n",
    "    if x in {'Four', 'Five or more'}:\n",
    "        return 'Four or more'\n",
    "    else:\n",
    "        return np.nan\n",
    "def _remap_fecal_quality(x):\n",
    "    if x == 'I tend to be constipated (have difficulty passing stool)':\n",
    "        return 'Constipated'\n",
    "    elif x == 'I tend to have diarrhea (watery stool)':\n",
    "        return 'Diarrhea'\n",
    "    elif x == 'I tend to have normal formed stool':\n",
    "        return 'Normal'\n",
    "    else:\n",
    "        return x\n",
    "def _remap_contraceptive(x):\n",
    "    if isinstance(x, str):\n",
    "        return x.split(',')[0]\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_summary(group):\n",
    "    fecal_data.clean_up_column(group)\n",
    "    \n",
    "    if group.type in {'Order', 'Frequency'}:\n",
    "        order = group.order\n",
    "    elif groupe.type in {'Categorical', 'Bool', 'Clinical'}:\n",
    "        order = list(group.groups)\n",
    "        \n",
    "    results = {'name': group.name,\n",
    "               'groups': order,\n",
    "               'extremes': group.extremes}\n",
    "    \n",
    "    map_, otu_, beta = fecal_data.return_dataset(group)\n",
    "    \n",
    "    grouped = map_.groupby(group.name).groups\n",
    "    group_ids = [grouped[o] for o in order]\n",
    "    extreme_ids = [grouped[o] for o in group.extremes]\n",
    "    \n",
    "    for metric in ['shannon_10k', 'PD_whole_tree_10k', 'observed_otus_10k', 'chao1_10k']:\n",
    "        results['%s_p_all' % metric] = alpha_test(metric, group_ids)\n",
    "        results['%s_p_extreme' % metric] = alpha_test(metric, extreme_ids)\n",
    "        \n",
    "        a_power, a_counts = subsample_power(\n",
    "            test=lambda x: alpha_test(metric, x),\n",
    "            samples=group_ids,\n",
    "            draw_mode=matched,\n",
    "            min_counts=5,\n",
    "            counts_interval=5,\n",
    "            max_counts=5,\n",
    "            num_runs=5,\n",
    "            num_iter=500,\n",
    "            )\n",
    "        results['%s_power_extreme'] = subsample_power(\n",
    "            test=lambda x: alpha_test(metric, x),\n",
    "            samples=extreme_ids,\n",
    "            draw_mode=matched,\n",
    "            min_counts=5,\n",
    "            counts_interval=5,\n",
    "            max_counts=5,\n",
    "            num_runs=5,\n",
    "            num_iter=500,\n",
    "            )\n",
    "    for metric in ['unweighted_unifrac', 'weighted_unifrac']:\n",
    "        results['%s_p_all' % metric.split('_')[0]] = \\\n",
    "            beta_test(metric, group, group_ids, permutations=999)\n",
    "        results['%s_p_extreme' % metric.split('_')[0]] = \\\n",
    "            beta_test(metric, group, extreme_ids, permutations=999)\n",
    "        results['%s_power_all']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for name, group in data_dictionary.iteritems():\n",
    "#     if group.type == 'AgContinous':\n",
    "#         continue\n",
    "name = 'AGE_CAT'\n",
    "group = data_dictionary['AGE_CAT']\n",
    "\n",
    "if group.type in {'Ordinal', 'Frequency'}:\n",
    "    order = group.order\n",
    "elif group.type in {'Categorical', 'Bool', 'Clinical'}:\n",
    "    order = list(group.groups)\n",
    "    \n",
    "results = {'name': group.name,\n",
    "           'groups': order,\n",
    "           'extremes': group.extremes}\n",
    "map_, otu_, beta = fecal_data.return_dataset(group)\n",
    "\n",
    "grouped = map_.groupby(group.name).groups\n",
    "group_ids = [grouped[o] for o in order]\n",
    "extreme_ids = [grouped[o] for o in group.extremes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_dir = '/Users/jwdebelius/Desktop/ag_summary/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists(os.path.join(save_dir, 'all_power/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for metric in ['PD_whole_tree_10k', 'shannon_10k']:\n",
    "    results['%s_p_all' % metric] = alpha_test(metric, group_ids)\n",
    "    results['%s_p_extreme' % metric] = alpha_test(metric, extreme_ids)\n",
    "\n",
    "    a_power, a_counts = subsample_power(\n",
    "                test=lambda x: alpha_test(metric, x),\n",
    "                samples=group_ids,\n",
    "                min_counts=10,\n",
    "                counts_interval=10,\n",
    "                max_counts=50,\n",
    "                num_runs=5,\n",
    "                num_iter=500,\n",
    "                )\n",
    "    with open(os.path.join(save_dir, 'all_power/%s/%s.p' % (metric, metric)), 'w') as f_:\n",
    "        pickle.dump((name, order, metric, a_power, a_counts), f_)\n",
    "    results['%s_eff_all' % metric] = (z_effect(a_counts, a_power).mean(),\n",
    "                                      confidence_bound(z_effect(a_counts, a_power)))\n",
    "    \n",
    "    e_power, e_counts = subsample_power(\n",
    "            test=lambda x: alpha_test(metric, x),\n",
    "            samples=extreme_ids,\n",
    "            min_counts=10,\n",
    "            counts_interval=10,\n",
    "            max_counts=50,\n",
    "            num_runs=5,\n",
    "            num_iter=500,\n",
    "            )\n",
    "    with open(os.path.join(save_dir, 'extreme_power/%s/%s.p' % (metric, metric)), 'w') as f_:\n",
    "        pickle.dump((name, order, metric, a_power, a_counts), f_)\n",
    "    results['%s_eff_ext' % metric] = (z_effect(e_counts, e_power).mean(), \n",
    "                                      confidence_bound(z_effect(e_counts, e_power)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for metric in ['unweighted', 'weighted']:\n",
    "    results['%s_unifrac_p_all' % metric] = beta_test(metric, group, group_ids, 999)\n",
    "    results['%s_unifrac_p_extreme' % metric] = beta_test(metric, group, extreme_ids, 999)\n",
    "\n",
    "    a_power, a_counts = subsample_power(\n",
    "                test=lambda x: beta_test(metric, group, group_ids, 99),\n",
    "                samples=group_ids,\n",
    "                min_counts=10,\n",
    "                counts_interval=10,\n",
    "                max_counts=50,\n",
    "                num_runs=5,\n",
    "                num_iter=500,\n",
    "                )\n",
    "    with open(os.path.join(save_dir, 'all_power/%s_unifrac/%s.p' % (metric, metric)), 'w') as f_:\n",
    "        pickle.dump((name, order, metric, a_power, a_counts), f_)\n",
    "    results['%s_unifrac_eff_all' % metric] = (z_effect(a_counts, a_power).mean(),\n",
    "                                              confidence_bound(z_effect(a_counts, a_power)))\n",
    "    \n",
    "    e_power, e_counts = subsample_power(\n",
    "            test=lambda x: beta_test(metric, group, group_ids, 99),\n",
    "            samples=extreme_ids,\n",
    "            min_counts=10,\n",
    "            counts_interval=10,\n",
    "            max_counts=50,\n",
    "            num_runs=5,\n",
    "            num_iter=500,\n",
    "            )\n",
    "    with open(os.path.join(save_dir, 'extreme_power/%s_unifrac/%s.p' % (metric, metric)), 'w') as f_:\n",
    "        pickle.dump((name, order, metric, a_power, a_counts), f_)\n",
    "    \n",
    "    results['%s_unifrac_eff_ext' % metric] = (z_effect(e_counts, e_power).mean(), \n",
    "                                              confidence_bound(z_effect(e_counts, e_power)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function beta_test in module __main__:\n",
      "\n",
      "beta_test(metric, group, ids=None, permutations=249)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(beta_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unweighted', 'weighted']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import scipy.stats\n",
    "\n",
    "from statsmodels.stats.power import FTestAnovaPower\n",
    "from scipy.stats import norm as z\n",
    "ft = FTestAnovaPower()\n",
    "\n",
    "\n",
    "def extrapolate_f(counts, pwr_, alpha=0.05):\n",
    "    \"\"\"Converts emperical power to extrapolated\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    counts : array\n",
    "        The number of observations which should be used in the final power\n",
    "        result.\n",
    "    pwr_ : array\n",
    "        The observed power. Each column corresponds to the number of\n",
    "        observations used in `cnts`. The rows correspond to different runs\n",
    "    cnts : array\n",
    "        The number of observations drawn to calculate the observed power.\n",
    "    alpha : float, optional\n",
    "        The critical value for power calculations.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    power : array\n",
    "        The extrapolated power for the number of observations given by `counts`\n",
    "\n",
    "    \"\"\"\n",
    "    # Gets the average emperical effect size\n",
    "    effs = np.zeros(pwr_.shape) * np.nan\n",
    "    for idx, pwr in enumerate(pwr_):\n",
    "        for idy, cnt in enumerate(counts):\n",
    "            try:\n",
    "                effs[idx, idy] = ft.solve_power(None, cnt, alpha, pwr[idy])\n",
    "            except:\n",
    "                pass\n",
    "    return effs\n",
    "#     eff_mean = np.nanmean(effs)\n",
    "    # Calculates the extrapolated power curve\n",
    "#     extr_pwr = ft.solve_power(effect_size=eff_mean,\n",
    "#                               nobs=counts,\n",
    "#                               alpha=0.05,\n",
    "#                               power=None)\n",
    "\n",
    "#     return extr_pwr\n",
    "\n",
    "def z_effect(counts, power, alpha=0.05):\n",
    "    \"\"\"Estimates the effect size for power based on the z distribution\n",
    "\n",
    "    This is based on the equations in\n",
    "        Lui, X.S. (2014) *Statistical power analysis for the social and\n",
    "        behavioral sciences: basic and advanced techniques.* New York:\n",
    "        Routledge. 378 pg.\n",
    "    The equation assumes a positive magnitude to the effect size and a\n",
    "    two-tailed test.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    counts : array\n",
    "        The number of observations for each power depth\n",
    "    power : array\n",
    "        The statistical power at the depth specified by `counts`\n",
    "    alpha : float\n",
    "        The critial value used to calculate the power\n",
    "\n",
    "    Returns\n",
    "    effect : array\n",
    "        T A standard measure of the difference between the underlying\n",
    "        populations\n",
    "    \"\"\"\n",
    "    z_diff = z.ppf(power) + z.ppf(1 - alpha / 2)\n",
    "    eff = np.sqrt(2 * np.square(z_diff) / counts)\n",
    "    eff = eff[np.isinf(eff) == False]\n",
    "    return eff\n",
    "\n",
    "\n",
    "def z_power(counts, eff, alpha=0.05):\n",
    "    \"\"\"Estimates power for a z distribution from an effect size\n",
    "\n",
    "    This is based on the equations in\n",
    "        Lui, X.S. (2014) *Statistical power analysis for the social and\n",
    "        behavioral sciences: basic and advanced techniques.* New York:\n",
    "        Routledge. 378 pg.\n",
    "    The equation assumes a positive magnitude to the effect size and a\n",
    "    two-tailed test.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    counts : array\n",
    "        The number of observations for each power depth\n",
    "    effect : float\n",
    "        A standard measure of the difference between the underlying populations\n",
    "     alpha : float\n",
    "        The critial value used to calculate the power\n",
    "\n",
    "    Returns\n",
    "    power : array\n",
    "        The statistical power at the depth specified by `counts`\n",
    "\n",
    "    \"\"\"\n",
    "    power = ((z.cdf(eff * np.sqrt(counts/2) - z.ppf(1 - alpha/2)) +\n",
    "             (z.cdf(z.ppf(alpha/2) - eff * np.sqrt(counts/2)))))\n",
    "    return power\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def beta_test(metric, group, ids, permutations=249):\n",
    "    ids = np.hstack(ids)\n",
    "    \n",
    "    beta_p = skbio.stats.distance.permanova(\n",
    "        distance_matrix=fecal_data.beta[metric].filter(ids),\n",
    "        grouping=fecal_data.map_.loc[ids],\n",
    "        column=group.name,\n",
    "        permutations=permutations,\n",
    "    )\n",
    "    return beta_p['p-value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function permanova in module skbio.stats.distance._permanova:\n",
      "\n",
      "permanova(distance_matrix, grouping, column=None, permutations=999)\n",
      "    Test for significant differences between groups using PERMANOVA.\n",
      "    \n",
      "    State: Experimental as of 0.4.0.\n",
      "    \n",
      "    Permutational Multivariate Analysis of Variance (PERMANOVA) is a\n",
      "    non-parametric method that tests whether two or more groups of objects\n",
      "    (e.g., samples) are significantly different based on a categorical factor.\n",
      "    It is conceptually similar to ANOVA except that it operates on a distance\n",
      "    matrix, which allows for multivariate analysis. PERMANOVA computes a\n",
      "    pseudo-F statistic.\n",
      "    \n",
      "    Statistical significance is assessed via a permutation test. The assignment\n",
      "    of objects to groups (`grouping`) is randomly permuted a number of times\n",
      "    (controlled via `permutations`). A pseudo-F statistic is computed for each\n",
      "    permutation and the p-value is the proportion of permuted pseudo-F\n",
      "    statisics that are equal to or greater than the original (unpermuted)\n",
      "    pseudo-F statistic.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    distance_matrix : DistanceMatrix\n",
      "        Distance matrix containing distances between objects (e.g., distances\n",
      "        between samples of microbial communities).\n",
      "    grouping : 1-D array_like or pandas.DataFrame\n",
      "        Vector indicating the assignment of objects to groups. For example,\n",
      "        these could be strings or integers denoting which group an object\n",
      "        belongs to. If `grouping` is 1-D ``array_like``, it must be the same\n",
      "        length and in the same order as the objects in `distance_matrix`. If\n",
      "        `grouping` is a ``DataFrame``, the column specified by `column` will be\n",
      "        used as the grouping vector. The ``DataFrame`` must be indexed by the\n",
      "        IDs in `distance_matrix` (i.e., the row labels must be distance matrix\n",
      "        IDs), but the order of IDs between `distance_matrix` and the\n",
      "        ``DataFrame`` need not be the same. All IDs in the distance matrix must\n",
      "        be present in the ``DataFrame``. Extra IDs in the ``DataFrame`` are\n",
      "        allowed (they are ignored in the calculations).\n",
      "    column : str, optional\n",
      "        Column name to use as the grouping vector if `grouping` is a\n",
      "        ``DataFrame``. Must be provided if `grouping` is a ``DataFrame``.\n",
      "        Cannot be provided if `grouping` is 1-D ``array_like``.\n",
      "    permutations : int, optional\n",
      "        Number of permutations to use when assessing statistical\n",
      "        significance. Must be greater than or equal to zero. If zero,\n",
      "        statistical significance calculations will be skipped and the p-value\n",
      "        will be ``np.nan``.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    pandas.Series\n",
      "        Results of the statistical test, including ``test statistic`` and\n",
      "        ``p-value``.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    anosim\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    See [1]_ for the original method reference, as well as ``vegan::adonis``,\n",
      "    available in R's vegan package [2]_.\n",
      "    \n",
      "    The p-value will be ``np.nan`` if `permutations` is zero.\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    .. [1] Anderson, Marti J. \"A new method for non-parametric multivariate\n",
      "       analysis of variance.\" Austral Ecology 26.1 (2001): 32-46.\n",
      "    \n",
      "    .. [2] http://cran.r-project.org/web/packages/vegan/index.html\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    See :mod:`skbio.stats.distance.anosim` for usage examples (both functions\n",
      "    provide similar interfaces).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(skbio.stats.distance.permanova)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map_.groupby('AGE_CAT').groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "partition_samples = [\n",
    "for a_metric in alpha_metrics:\n",
    "    results['%s_p' % a_metric] = alpha_test(a_metric, group)\n",
    "    results['%s_power' % a_metric] = subsample_power(\n",
    "        test=lambda x: alpha_test(metric, group, x),\n",
    "        \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map_.groupby(group.name).groups.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def alpha_test(metric, ids):\n",
    "    alpha = [map_.loc[i, metric] for i in ids]\n",
    "    return scipy.stats.kruskal(*alpha)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skbio.stats.power import confidence_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function confidence_bound in module skbio.stats.power:\n",
      "\n",
      "confidence_bound(vec, alpha=0.05, df=None, axis=None)\n",
      "    Calculates a confidence bound assuming a normal distribution\n",
      "    \n",
      "    State: Experimental as of 0.4.0.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    vec : array_like\n",
      "        The array of values to use in the bound calculation.\n",
      "    alpha : float, optional\n",
      "        The critical value, used for the confidence bound calculation.\n",
      "    df : float, optional\n",
      "        The degrees of freedom associated with the\n",
      "        distribution. If None is given, df is assumed to be the number of\n",
      "        elements in specified axis.\n",
      "    axis : positive int, optional\n",
      "        The axis over which to take the deviation. When axis\n",
      "        is None, a single value will be calculated for the whole matrix.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    bound : float\n",
      "        The confidence bound around the mean. The confidence interval is\n",
      "        [mean - bound, mean + bound].\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(confidence_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
