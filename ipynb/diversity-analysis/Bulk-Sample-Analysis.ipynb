{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to evaluate a set of metadata categories to identify factors which may be interesting to pursue further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import skbio\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from skbio.stats.power import subsample_power, confidence_bound\n",
    "\n",
    "from americangut.ag_data_dictionary import ag_data_dictionary\n",
    "from americangut.ag_data import AgData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's select a dataset to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bodysite = 'fecal'\n",
    "sequence_trim = '100nt'\n",
    "rarefaction_depth = '10k'\n",
    "\n",
    "use_subset = False\n",
    "use_one_sample = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's select a list of groups to interogate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fecal_data = AgData(bodysite=bodysite, \n",
    "                    trim=sequence_trim, \n",
    "                    depth=rarefaction_depth, \n",
    "                    sub_participants=use_subset, \n",
    "                    one_sample=use_one_sample)\n",
    "fecal_data.drop_alpha_outliers()\n",
    "\n",
    "fecal_data.drop_bmi_outliers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def alpha_test(metric, map_, ids):\n",
    "    alpha = [map_.loc[i, metric] for i in ids]\n",
    "    return scipy.stats.kruskal(*alpha)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def beta_test(metric, group, ids, permutations=249):\n",
    "    ids = np.hstack(ids)\n",
    "    \n",
    "    beta_p = skbio.stats.distance.permanova(\n",
    "        distance_matrix=fecal_data.beta[metric].filter(ids),\n",
    "        grouping=fecal_data.map_.loc[ids],\n",
    "        column=group.name,\n",
    "        permutations=permutations,\n",
    "    )\n",
    "    return beta_p['p-value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_summary(group):\n",
    "    fecal_data.clean_up_column(group)\n",
    "    \n",
    "    order = group.order\n",
    "        \n",
    "    results = {'name': group.name,\n",
    "               'groups': order,\n",
    "               'extremes': group.extremes}\n",
    "    \n",
    "    map_, otu_, beta = fecal_data.return_dataset(group)\n",
    "    \n",
    "    grouped = map_.groupby(group.name).groups\n",
    "    group_ids = [grouped[o] for o in order]\n",
    "    extreme_ids = [grouped[o] for o in group.extremes]\n",
    "\n",
    "    for metric in ['PD_whole_tree_10k', 'shannon_10k']:\n",
    "        results['%s_p_all' % metric] = alpha_test(metric, map_, group_ids)\n",
    "        results['%s_p_extreme' % metric] = alpha_test(metric, map_, extreme_ids)\n",
    "\n",
    "        a_power, a_counts = subsample_power(\n",
    "                    test=lambda x: alpha_test(metric, map_, x),\n",
    "                    samples=group_ids,\n",
    "                    min_counts=5,\n",
    "                    counts_interval=10,\n",
    "                    max_counts=50,\n",
    "                    num_runs=5,\n",
    "                    num_iter=500,\n",
    "                    )\n",
    "        with open(os.path.join(save_dir, 'all_power/%s/%s.p' % (metric, group)), 'w') as f_:\n",
    "            pickle.dump((group.name, group.order, metric, a_power, a_counts), f_)\n",
    "        results['%s_eff_all' % metric] = (z_effect(a_counts, a_power).mean(),\n",
    "                                          confidence_bound(z_effect(a_counts, a_power)))\n",
    "\n",
    "        e_power, e_counts = subsample_power(\n",
    "                test=lambda x: alpha_test(metric, map_, x),\n",
    "                samples=extreme_ids,\n",
    "                min_counts=5,\n",
    "                counts_interval=10,\n",
    "                max_counts=50,\n",
    "                num_runs=5,\n",
    "                num_iter=500,\n",
    "                )\n",
    "        with open(os.path.join(save_dir, 'extreme_power/%s/%s.p' % (metric, group)), 'w') as f_:\n",
    "            pickle.dump((group.name, group.order, metric, a_power, a_counts), f_)\n",
    "        results['%s_eff_ext' % metric] = (z_effect(e_counts, e_power).mean(), \n",
    "                                          confidence_bound(z_effect(e_counts, e_power)))\n",
    "\n",
    "    for metric in ['unweighted_unifrac', 'weighted_unifrac']:\n",
    "        results['%s_unifrac_p_all' % metric] = beta_test(metric, group, group_ids, 999)\n",
    "        results['%s_unifrac_p_extreme' % metric] = beta_test(metric, group, extreme_ids, 999)\n",
    "\n",
    "        a_power, a_counts = subsample_power(\n",
    "                    test=lambda x: beta_test(metric, group, group_ids, 99),\n",
    "                    samples=group_ids,\n",
    "                    min_counts=10,\n",
    "                    counts_interval=10,\n",
    "                    max_counts=50,\n",
    "                    num_runs=5,\n",
    "                    num_iter=500,\n",
    "                    )\n",
    "        with open(os.path.join(save_dir, 'all_power/%s_unifrac/%s.p' % (metric, group)), 'w') as f_:\n",
    "            pickle.dump((name, order, metric, a_power, a_counts), f_)\n",
    "        results['%s_unifrac_eff_all' % metric] = (z_effect(a_counts, a_power).mean(),\n",
    "                                                  confidence_bound(z_effect(a_counts, a_power)))\n",
    "\n",
    "        e_power, e_counts = subsample_power(\n",
    "                test=lambda x: beta_test(metric, group, group_ids, 99),\n",
    "                samples=extreme_ids,\n",
    "                min_counts=10,\n",
    "                counts_interval=10,\n",
    "                max_counts=50,\n",
    "                num_runs=5,\n",
    "                num_iter=500,\n",
    "                )\n",
    "        with open(os.path.join(save_dir, 'extreme_power/%s_unifrac/%s.p' % (metric, group)), 'w') as f_:\n",
    "            pickle.dump((group.name, group.order, metric, a_power, a_counts), f_)\n",
    "\n",
    "        results['%s_unifrac_eff_ext' % metric] = (z_effect(e_counts, e_power).mean(), \n",
    "                                                  confidence_bound(z_effect(e_counts, e_power)))\n",
    "        \n",
    "    with open(os.path.join(save_dir, 'summary/%s.p' % group), 'w') as f_:\n",
    "        pickle.dump((results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "generate_summary(ag_data_dictionary['AGE_CAT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for name, group in data_dictionary.iteritems():\n",
    "#     if group.type == 'AgContinous':\n",
    "#         continue\n",
    "name = 'AGE_CAT'\n",
    "group = data_dictionary['AGE_CAT']\n",
    "\n",
    "if group.type in {'Ordinal', 'Frequency'}:\n",
    "    order = group.order\n",
    "elif group.type in {'Categorical', 'Bool', 'Clinical'}:\n",
    "    order = list(group.groups)\n",
    "    \n",
    "results = {'name': group.name,\n",
    "           'groups': order,\n",
    "           'extremes': group.extremes}\n",
    "map_, otu_, beta = fecal_data.return_dataset(group)\n",
    "\n",
    "grouped = map_.groupby(group.name).groups\n",
    "group_ids = [grouped[o] for o in order]\n",
    "extreme_ids = [grouped[o] for o in group.extremes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_dir = '/Users/jwdebelius/Desktop/ag_summary/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.path.exists(os.path.join(save_dir, 'all_power/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "help(beta_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "beta.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import scipy.stats\n",
    "\n",
    "from statsmodels.stats.power import FTestAnovaPower\n",
    "from scipy.stats import norm as z\n",
    "ft = FTestAnovaPower()\n",
    "\n",
    "\n",
    "def extrapolate_f(counts, pwr_, alpha=0.05):\n",
    "    \"\"\"Converts emperical power to extrapolated\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    counts : array\n",
    "        The number of observations which should be used in the final power\n",
    "        result.\n",
    "    pwr_ : array\n",
    "        The observed power. Each column corresponds to the number of\n",
    "        observations used in `cnts`. The rows correspond to different runs\n",
    "    cnts : array\n",
    "        The number of observations drawn to calculate the observed power.\n",
    "    alpha : float, optional\n",
    "        The critical value for power calculations.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    power : array\n",
    "        The extrapolated power for the number of observations given by `counts`\n",
    "\n",
    "    \"\"\"\n",
    "    # Gets the average emperical effect size\n",
    "    effs = np.zeros(pwr_.shape) * np.nan\n",
    "    for idx, pwr in enumerate(pwr_):\n",
    "        for idy, cnt in enumerate(counts):\n",
    "            try:\n",
    "                effs[idx, idy] = ft.solve_power(None, cnt, alpha, pwr[idy])\n",
    "            except:\n",
    "                pass\n",
    "    return effs\n",
    "#     eff_mean = np.nanmean(effs)\n",
    "    # Calculates the extrapolated power curve\n",
    "#     extr_pwr = ft.solve_power(effect_size=eff_mean,\n",
    "#                               nobs=counts,\n",
    "#                               alpha=0.05,\n",
    "#                               power=None)\n",
    "\n",
    "#     return extr_pwr\n",
    "\n",
    "def z_effect(counts, power, alpha=0.05):\n",
    "    \"\"\"Estimates the effect size for power based on the z distribution\n",
    "\n",
    "    This is based on the equations in\n",
    "        Lui, X.S. (2014) *Statistical power analysis for the social and\n",
    "        behavioral sciences: basic and advanced techniques.* New York:\n",
    "        Routledge. 378 pg.\n",
    "    The equation assumes a positive magnitude to the effect size and a\n",
    "    two-tailed test.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    counts : array\n",
    "        The number of observations for each power depth\n",
    "    power : array\n",
    "        The statistical power at the depth specified by `counts`\n",
    "    alpha : float\n",
    "        The critial value used to calculate the power\n",
    "\n",
    "    Returns\n",
    "    effect : array\n",
    "        T A standard measure of the difference between the underlying\n",
    "        populations\n",
    "    \"\"\"\n",
    "    z_diff = z.ppf(power) + z.ppf(1 - alpha / 2)\n",
    "    eff = np.sqrt(2 * np.square(z_diff) / counts)\n",
    "    eff = eff[np.isinf(eff) == False]\n",
    "    return eff\n",
    "\n",
    "\n",
    "def z_power(counts, eff, alpha=0.05):\n",
    "    \"\"\"Estimates power for a z distribution from an effect size\n",
    "\n",
    "    This is based on the equations in\n",
    "        Lui, X.S. (2014) *Statistical power analysis for the social and\n",
    "        behavioral sciences: basic and advanced techniques.* New York:\n",
    "        Routledge. 378 pg.\n",
    "    The equation assumes a positive magnitude to the effect size and a\n",
    "    two-tailed test.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    counts : array\n",
    "        The number of observations for each power depth\n",
    "    effect : float\n",
    "        A standard measure of the difference between the underlying populations\n",
    "     alpha : float\n",
    "        The critial value used to calculate the power\n",
    "\n",
    "    Returns\n",
    "    power : array\n",
    "        The statistical power at the depth specified by `counts`\n",
    "\n",
    "    \"\"\"\n",
    "    power = ((z.cdf(eff * np.sqrt(counts/2) - z.ppf(1 - alpha/2)) +\n",
    "             (z.cdf(z.ppf(alpha/2) - eff * np.sqrt(counts/2)))))\n",
    "    return power\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "help(skbio.stats.distance.permanova)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map_.groupby('AGE_CAT').groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "partition_samples = [\n",
    "for a_metric in alpha_metrics:\n",
    "    results['%s_p' % a_metric] = alpha_test(a_metric, group)\n",
    "    results['%s_power' % a_metric] = subsample_power(\n",
    "        test=lambda x: alpha_test(metric, group, x),\n",
    "        \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map_.groupby(group.name).groups.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def alpha_test(metric, ids):\n",
    "    alpha = [map_.loc[i, metric] for i in ids]\n",
    "    return scipy.stats.kruskal(*alpha)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skbio.stats.power import confidence_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "help(confidence_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
