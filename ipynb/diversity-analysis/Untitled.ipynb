{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import use\n",
    "use('Agg')  #noqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from scipy.stats import norm as z\n",
    "import skbio\n",
    "\n",
    "from skbio.stats.power import subsample_power, confidence_bound\n",
    "\n",
    "from americangut.ag_data import AgData, ag_data_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BODYSITE = 'fecal'\n",
    "TRIM = '100nt'\n",
    "DEPTH = '10k'\n",
    "ONE_SAMPLE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _alpha_test(metric, map_, ids):\n",
    "    \"\"\"Tests alpha diversity with a krusal wallis test\"\"\"\n",
    "    alpha = [map_.loc[i, metric] for i in ids]\n",
    "    return scipy.stats.kruskal(*alpha)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _beta_test(metric, group, data, ids, permutations=249):\n",
    "    \"\"\"Tests beta diversity with a permanova\"\"\"\n",
    "    ids = np.hstack(ids)\n",
    "    beta_p = skbio.stats.distance.permanova(\n",
    "        distance_matrix=data.beta[metric].filter(ids),\n",
    "        grouping=data.map_.loc[ids],\n",
    "        column=group.name,\n",
    "        permutations=permutations,\n",
    "    )\n",
    "    return beta_p['p-value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def z_effect(counts, power, alpha=0.05):\n",
    "    \"\"\"Estimates the effect size for power based on the z distribution\n",
    "\n",
    "    This is based on the equations in\n",
    "        Lui, X.S. (2014) *Statistical power analysis for the social and\n",
    "        behavioral sciences: basic and advanced techniques.* New York:\n",
    "        Routledge. 378 pg.\n",
    "    The equation assumes a positive magnitude to the effect size and a\n",
    "    two-tailed test.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    counts : array\n",
    "        The number of observations for each power depth\n",
    "    power : array\n",
    "        The statistical power at the depth specified by `counts`\n",
    "    alpha : float\n",
    "        The critial value used to calculate the power\n",
    "\n",
    "    Returns\n",
    "    effect : array\n",
    "        T A standard measure of the difference between the underlying\n",
    "        populations\n",
    "    \"\"\"\n",
    "    z_diff = z.ppf(power) + z.ppf(1 - alpha / 2)\n",
    "    eff = np.sqrt(2 * np.square(z_diff) / counts)\n",
    "    eff = eff[np.isinf(eff) == False]\n",
    "    return eff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "group = ag_data_dictionary['AGE_CAT']\n",
    "subset = False\n",
    "save_dir = '/Users/jwdebelius/Desktop/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.55 s, sys: 333 ms, total: 7.88 s\n",
      "Wall time: 7.97 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "data = AgData(bodysite=BODYSITE,\n",
    "              trim=TRIM,\n",
    "              depth=DEPTH,\n",
    "              one_sample=ONE_SAMPLE,\n",
    "              sub_participants=subset,\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 944 ms, sys: 137 ms, total: 1.08 s\n",
      "Wall time: 1.08 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data.drop_alpha_outliers()\n",
    "data.drop_bmi_outliers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 466 ms, sys: 33.7 ms, total: 500 ms\n",
      "Wall time: 493 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data.clean_group(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 1e+03 ns, total: 5 µs\n",
      "Wall time: 12.2 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = {'name': group.name,\n",
    "           'groups': group.order,\n",
    "           'extremes': group.extremes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.14 s, sys: 60.7 ms, total: 1.2 s\n",
      "Wall time: 1.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "map_, otu_, beta = data.return_dataset(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 613 µs, sys: 34 µs, total: 647 µs\n",
      "Wall time: 630 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grouped = data.map_.groupby(group.name).groups\n",
    "group_ids = [grouped[o] for o in group.order]\n",
    "extreme_ids = [grouped[o] for o in group.extremes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metric = 'PD_whole_tree_10k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.64 ms, sys: 1.12 ms, total: 8.76 ms\n",
      "Wall time: 7.86 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results['%s_p_all' % metric] = _alpha_test(metric, map_, group_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 ms, sys: 500 µs, total: 3.5 ms\n",
      "Wall time: 3.02 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results['%s_p_extreme' % metric] = _alpha_test(metric, map_,\n",
    "                                                      extreme_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 46 s, sys: 106 ms, total: 46.1 s\n",
      "Wall time: 46.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    " a_power, a_counts = subsample_power(\n",
    "                    test=lambda x: _alpha_test(metric, data.map_, x),\n",
    "                    samples=group_ids,\n",
    "                    min_counts=5,\n",
    "                    counts_interval=10,\n",
    "                    max_counts=50,\n",
    "                    num_runs=5,\n",
    "                    num_iter=500,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.48 ms, sys: 696 µs, total: 2.17 ms\n",
      "Wall time: 6.16 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "a_eff = z_effect(a_counts, a_power)\n",
    "results['%s_eff_all' % metric] = a_eff.mean()\n",
    "results['%s_eff_lo' % metric] = a_eff.mean() - confidence_bound(a_eff)\n",
    "results['%s_eff_hi' % metric] = a_eff.mean() + confidence_bound(a_eff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 46.9 s, sys: 158 ms, total: 47 s\n",
      "Wall time: 47.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "e_power, e_counts = subsample_power(\n",
    "                    test=lambda x: _alpha_test(metric, data.map_, x),\n",
    "                    samples=group_ids,\n",
    "                    min_counts=5,\n",
    "                    counts_interval=10,\n",
    "                    max_counts=50,\n",
    "                    num_runs=5,\n",
    "                    num_iter=500,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.27 ms, sys: 270 µs, total: 1.54 ms\n",
      "Wall time: 1.35 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "e_eff = z_effect(a_counts, a_power)\n",
    "results['%s_eff_exe' % metric] = e_eff.mean()\n",
    "results['%s_eff_exe_lo' % metric] = e_eff.mean() - \\\n",
    "    confidence_bound(e_eff)\n",
    "results['%s_eff_exe_hi' % metric] = e_eff.mean() + \\\n",
    "    confidence_bound(e_eff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metric = 'unweighted_unifrac'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 28s, sys: 59.9 s, total: 3min 28s\n",
      "Wall time: 3min 28s\n",
      "CPU times: user 19.6 s, sys: 4.43 s, total: 24 s\n",
      "Wall time: 24.1 s\n"
     ]
    }
   ],
   "source": [
    "%time results['%s_unifrac_p_all' % metric] = _beta_test(metric, group, data, group_ids, 999)\n",
    "%time results['%s_unifrac_p_extreme' % metric] = _beta_test(metric, group, data, extreme_ids, 999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 34s, sys: 2.11 s, total: 2min 36s\n",
      "Wall time: 2min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "a_power, a_counts = subsample_power(\n",
    "                    test=lambda x: _beta_test(metric, group, data, x, 99),\n",
    "                    samples=group_ids,\n",
    "                    min_counts=5,\n",
    "                    counts_interval=10,\n",
    "                    max_counts=50,\n",
    "                    num_runs=5,\n",
    "                    num_iter=99,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13min 6s, sys: 10.3 s, total: 13min 16s\n",
      "Wall time: 13min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "a_power, a_counts = subsample_power(\n",
    "                    test=lambda x: _beta_test(metric, group, data, x, 99),\n",
    "                    samples=group_ids,\n",
    "                    min_counts=5,\n",
    "                    counts_interval=10,\n",
    "                    max_counts=50,\n",
    "                    num_runs=5,\n",
    "                    num_iter=500,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.58 ms, sys: 381 µs, total: 1.96 ms\n",
      "Wall time: 1.69 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "a_eff = z_effect(a_counts, a_power)\n",
    "results['%s_eff_all' % metric] = a_eff.mean()\n",
    "results['%s_eff_all_lo' % metric] = a_eff.mean() - \\\n",
    "    confidence_bound(a_eff)\n",
    "results['%s_eff_all_hi' % metric] = a_eff.mean() + \\\n",
    "    confidence_bound(a_eff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 4s, sys: 3.06 s, total: 5min 7s\n",
      "Wall time: 5min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "e_power, e_counts = subsample_power(\n",
    "                    test=lambda x: _beta_test(metric, group, data, x, 99),\n",
    "                    samples=extreme_ids,\n",
    "                    min_counts=5,\n",
    "                    counts_interval=10,\n",
    "                    max_counts=50,\n",
    "                    num_runs=5,\n",
    "                    num_iter=500,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.68 ms, sys: 411 µs, total: 2.09 ms\n",
      "Wall time: 1.84 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "e_eff = z_effect(a_counts, a_power)\n",
    "results['%s_eff_exe' % metric] = e_eff.mean()\n",
    "results['%s_eff_exe_lo' % metric] = e_eff.mean() - \\\n",
    "    confidence_bound(e_eff)\n",
    "results['%s_eff_exe_hi' % metric] = e_eff.mean() + \\\n",
    "    confidence_bound(e_eff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 406 µs, sys: 1.15 ms, total: 1.55 ms\n",
      "Wall time: 1.14 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if not os.path.exists(os.path.join(save_dir, 'summary')):\n",
    "    os.makedirs(os.path.join(save_dir, 'summary'))\n",
    "for metric in ['PD_whole_tree_10k', 'shannon_10k', 'unweighted_unifrac',\n",
    "               'weighted_unifrac']:\n",
    "    if not os.path.exists(os.path.join(save_dir, 'all_power/%s') % metric):\n",
    "        os.makedirs(os.path.join(save_dir, 'all_power/%s') % metric)\n",
    "    if not os.path.exists(\n",
    "            os.path.join(save_dir, 'extreme_power/%s' % metric)):\n",
    "        os.makedirs(os.path.join(save_dir, 'extreme_power/%s') % metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 8s, sys: 750 ms, total: 3min 8s\n",
      "Wall time: 3min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for metric in ['PD_whole_tree_10k', 'shannon_10k']:\n",
    "    results['%s_p_all' % metric] = _alpha_test(metric, map_, group_ids)\n",
    "    results['%s_p_extreme' % metric] = _alpha_test(metric, map_,\n",
    "                                                  extreme_ids)\n",
    "\n",
    "    a_power, a_counts = subsample_power(\n",
    "                test=lambda x: _alpha_test(metric, data.map_, x),\n",
    "                samples=group_ids,\n",
    "                min_counts=5,\n",
    "                counts_interval=10,\n",
    "                max_counts=50,\n",
    "                num_runs=5,\n",
    "                num_iter=500,\n",
    "                )\n",
    "    with open(os.path.join(save_dir, 'all_power/%s/%s.p'\n",
    "                           % (metric, group.name)), 'w') as f_:\n",
    "        pickle.dump((group.name, group.order, metric, a_power, a_counts),\n",
    "                    f_)\n",
    "    a_eff = z_effect(a_counts, a_power)\n",
    "    results['%s_eff_all' % metric] = a_eff.mean()\n",
    "    results['%s_eff_all_lo' % metric] = a_eff.mean() - \\\n",
    "        confidence_bound(a_eff)\n",
    "    results['%s_eff_all_hi' % metric] = a_eff.mean() + \\\n",
    "        confidence_bound(a_eff)\n",
    "\n",
    "    e_power, e_counts = subsample_power(\n",
    "                test=lambda x: _alpha_test(metric, data.map_, x),\n",
    "                samples=group_ids,\n",
    "                min_counts=5,\n",
    "                counts_interval=10,\n",
    "                max_counts=50,\n",
    "                num_runs=5,\n",
    "                num_iter=500,\n",
    "                )\n",
    "    with open(os.path.join(save_dir, 'extreme_power/%s/%s.p'\n",
    "                           % (metric, group.name)), 'w') as f_:\n",
    "        pickle.dump((group.name, group.order, metric, a_power, a_counts),\n",
    "                    f_)\n",
    "    e_eff = z_effect(a_counts, a_power)\n",
    "    results['%s_eff_exe' % metric] = e_eff.mean()\n",
    "    results['%s_eff_exe_lo' % metric] = e_eff.mean() - \\\n",
    "        confidence_bound(e_eff)\n",
    "    results['%s_eff_exe_hi' % metric] = e_eff.mean() + \\\n",
    "        confidence_bound(e_eff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 42min 38s, sys: 3min 4s, total: 45min 43s\n",
      "Wall time: 1h 10min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "    for metric in ['unweighted_unifrac', 'weighted_unifrac']:\n",
    "        results['%s_unifrac_p_all' % metric] = \\\n",
    "            _beta_test(metric, group, data, group_ids, 999)\n",
    "        results['%s_unifrac_p_extreme' % metric] = \\\n",
    "            _beta_test(metric, group, data, extreme_ids, 999)\n",
    "\n",
    "        a_power, a_counts = subsample_power(\n",
    "                    test=lambda x: _beta_test(metric, group, data, x, 99),\n",
    "                    samples=group_ids,\n",
    "                    min_counts=5,\n",
    "                    counts_interval=10,\n",
    "                    max_counts=50,\n",
    "                    num_runs=5,\n",
    "                    num_iter=500,\n",
    "                    )\n",
    "        with open(os.path.join(save_dir, 'all_power/%s/%s.p'\n",
    "                               % (metric, group.name)), 'w') as f_:\n",
    "            pickle.dump((group.name, group.order, metric, a_power, a_counts),\n",
    "                        f_)\n",
    "\n",
    "        a_eff = z_effect(a_counts, a_power)\n",
    "        results['%s_eff_all' % metric] = a_eff.mean()\n",
    "        results['%s_eff_all_lo' % metric] = a_eff.mean() - \\\n",
    "            confidence_bound(a_eff)\n",
    "        results['%s_eff_all_hi' % metric] = a_eff.mean() + \\\n",
    "            confidence_bound(a_eff)\n",
    "\n",
    "        e_power, e_counts = subsample_power(\n",
    "                    test=lambda x: _beta_test(metric, group, data, x, 99),\n",
    "                    samples=extreme_ids,\n",
    "                    min_counts=5,\n",
    "                    counts_interval=10,\n",
    "                    max_counts=50,\n",
    "                    num_runs=5,\n",
    "                    num_iter=500,\n",
    "                    )\n",
    "        with open(os.path.join(save_dir, 'extreme_power/%s/%s.p'\n",
    "                               % (metric, group.name)), 'w') as f_:\n",
    "            pickle.dump((group.name, group.order, metric, e_power, e_counts),\n",
    "                        f_)\n",
    "\n",
    "        e_eff = z_effect(a_counts, a_power)\n",
    "        results['%s_eff_exe' % metric] = e_eff.mean()\n",
    "        results['%s_eff_exe_lo' % metric] = e_eff.mean() - \\\n",
    "            confidence_bound(e_eff)\n",
    "        results['%s_eff_exe_hi' % metric] = e_eff.mean() + \\\n",
    "            confidence_bound(e_eff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_summary(group, subset, save_dir):\n",
    "    \"\"\"...\"\"\"\n",
    "    if not os.path.exists(os.path.join(save_dir, 'summary')):\n",
    "        os.makedirs(os.path.join(save_dir, 'summary'))\n",
    "    for metric in ['PD_whole_tree_10k', 'shannon_10k', 'unweighted_unifrac',\n",
    "                   'weighted_unifrac']:\n",
    "        if not os.path.exists(os.path.join(save_dir, 'all_power/%s') % metric):\n",
    "            os.makedirs(os.path.join(save_dir, 'all_power/%s') % metric)\n",
    "        if not os.path.exists(\n",
    "                os.path.join(save_dir, 'extreme_power/%s' % metric)):\n",
    "            os.makedirs(os.path.join(save_dir, 'extreme_power/%s') % metric)\n",
    "\n",
    "    # Loads the dataset\n",
    "    data = AgData(bodysite=BODYSITE,\n",
    "                  trim=TRIM,\n",
    "                  depth=DEPTH,\n",
    "                  one_sample=ONE_SAMPLE,\n",
    "                  sub_participants=subset,\n",
    "                  )\n",
    "    data.drop_alpha_outliers()\n",
    "    data.drop_bmi_outliers()\n",
    "    # Cleans up the column of interst\n",
    "    data.clean_group(group)\n",
    "\n",
    "    results = {'name': group.name,\n",
    "               'groups': group.order,\n",
    "               'extremes': group.extremes}\n",
    "\n",
    "    grouped = map_.groupby(group.name).groups\n",
    "    group_ids = [grouped[o] for o in group.order]\n",
    "    extreme_ids = [grouped[o] for o in group.extremes]\n",
    "\n",
    "    for metric in ['PD_whole_tree_10k', 'shannon_10k']:\n",
    "        results['%s_p_all' % metric] = _alpha_test(metric, map_, group_ids)\n",
    "        results['%s_p_extreme' % metric] = _alpha_test(metric, map_,\n",
    "                                                       extreme_ids)\n",
    "\n",
    "        a_power, a_counts = subsample_power(\n",
    "                    test=lambda x: _alpha_test(metric, data.map_, x),\n",
    "                    samples=group_ids,\n",
    "                    min_counts=5,\n",
    "                    counts_interval=10,\n",
    "                    max_counts=50,\n",
    "                    num_runs=5,\n",
    "                    num_iter=500,\n",
    "                    )\n",
    "        with open(os.path.join(save_dir, 'all_power/%s/%s.p'\n",
    "                               % (metric, group.name)), 'w') as f_:\n",
    "            pickle.dump((group.name, group.order, metric, a_power, a_counts),\n",
    "                        f_)\n",
    "        a_eff = z_effect(a_counts, a_power)\n",
    "        results['%s_eff_all' % metric] = a_eff.mean()\n",
    "        results['%s_eff_all_lo' % metric] = a_eff.mean() - \\\n",
    "            confidence_bound(a_eff)\n",
    "        results['%s_eff_all_hi' % metric] = a_eff.mean() + \\\n",
    "            confidence_bound(a_eff)\n",
    "\n",
    "        e_power, e_counts = subsample_power(\n",
    "                    test=lambda x: _alpha_test(metric, data.map_, x),\n",
    "                    samples=group_ids,\n",
    "                    min_counts=5,\n",
    "                    counts_interval=10,\n",
    "                    max_counts=50,\n",
    "                    num_runs=5,\n",
    "                    num_iter=500,\n",
    "                    )\n",
    "        with open(os.path.join(save_dir, 'extreme_power/%s/%s.p'\n",
    "                               % (metric, group.name)), 'w') as f_:\n",
    "            pickle.dump((group.name, group.order, metric, e_power, e_counts),\n",
    "                        f_)\n",
    "        e_eff = z_effect(a_counts, a_power)\n",
    "        results['%s_eff_exe' % metric] = e_eff.mean()\n",
    "        results['%s_eff_exe_lo' % metric] = e_eff.mean() - \\\n",
    "            confidence_bound(e_eff)\n",
    "        results['%s_eff_exe_hi' % metric] = e_eff.mean() + \\\n",
    "            confidence_bound(e_eff)\n",
    "\n",
    "    for metric in ['unweighted_unifrac', 'weighted_unifrac']:\n",
    "        results['%s_unifrac_p_all' % metric] = \\\n",
    "            _beta_test(metric, group, data, group_ids, 999)\n",
    "        results['%s_unifrac_p_extreme' % metric] = \\\n",
    "            _beta_test(metric, group, data, extreme_ids, 999)\n",
    "\n",
    "        a_power, a_counts = subsample_power(\n",
    "                    test=lambda x: _beta_test(metric, group, data, x, 99),\n",
    "                    samples=group_ids,\n",
    "                    min_counts=5,\n",
    "                    counts_interval=10,\n",
    "                    max_counts=50,\n",
    "                    num_runs=5,\n",
    "                    num_iter=500,\n",
    "                    )\n",
    "        with open(os.path.join(save_dir, 'all_power/%s/%s.p'\n",
    "                               % (metric, group.name)), 'w') as f_:\n",
    "            pickle.dump((group.name, group.order, metric, a_power, a_counts),\n",
    "                        f_)\n",
    "\n",
    "        a_eff = z_effect(a_counts, a_power)\n",
    "        results['%s_eff_all' % metric] = a_eff.mean()\n",
    "        results['%s_eff_all_lo' % metric] = a_eff.mean() - \\\n",
    "            confidence_bound(a_eff)\n",
    "        results['%s_eff_all_hi' % metric] = a_eff.mean() + \\\n",
    "            confidence_bound(a_eff)\n",
    "\n",
    "        e_power, e_counts = subsample_power(\n",
    "                    test=lambda x: _beta_test(metric, group, data, x, 99),\n",
    "                    samples=extreme_ids,\n",
    "                    min_counts=5,\n",
    "                    counts_interval=10,\n",
    "                    max_counts=50,\n",
    "                    num_runs=5,\n",
    "                    num_iter=500,\n",
    "                    )\n",
    "        with open(os.path.join(save_dir, 'extreme_power/%s/%s.p'\n",
    "                               % (metric, group.name)), 'w') as f_:\n",
    "            pickle.dump((group.name, group.order, metric, e_power, e_counts),\n",
    "                        f_)\n",
    "\n",
    "        e_eff = z_effect(a_counts, a_power)\n",
    "        results['%s_eff_exe' % metric] = e_eff.mean()\n",
    "        results['%s_eff_exe_lo' % metric] = e_eff.mean() - \\\n",
    "            confidence_bound(e_eff)\n",
    "        results['%s_eff_exe_hi' % metric] = e_eff.mean() + \\\n",
    "            confidence_bound(e_eff)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# pool = Pool(32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 45min 56s, sys: 2min 48s, total: 48min 45s\n",
      "Wall time: 49min\n"
     ]
    }
   ],
   "source": [
    "%time generate_summary(group, subset, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ag_data_dictionary.keys())/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SLEEP_DURATION',\n",
       " 'SMOKING_FREQUENCY',\n",
       " 'SUGARY_SWEETS_FREQUENCY',\n",
       " 'TYPES_OF_PLANTS',\n",
       " 'VEGETABLE_FREQUENCY',\n",
       " 'VITAMIN_B_SUPPLEMENT_FREQUENCY',\n",
       " 'VITAMIN_D_SUPPLEMENT_FREQUENCY',\n",
       " 'WEIGHT_CHANGE']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(ag_data_dictionary.keys())[45:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
