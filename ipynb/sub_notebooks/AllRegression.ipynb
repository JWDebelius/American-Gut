{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>License</strong>: BSD<br/>\n",
    "<strong>Copyright</strong>: Copyright The American Gut Project, 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.load_extensions('calico-spell-check', 'calico-document-tools')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.load_extensions('calico-spell-check', 'calico-document-tools')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # This cell allows us to render the notebook in the way we wish no matter where\n",
    "# # the notebook is rendered.\n",
    "# from IPython.core.display import HTML\n",
    "# css_file = '../ag.css'\n",
    "# HTML(open(css_file, \"r\").read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"intro\"></a>\n",
    "___\n",
    "*Note*: this notebook will likely require signifigant manual interaction is more intended to document exploratory analysis than to be adapted for other projects.\n",
    "___\n",
    "\n",
    "# [Title]\n",
    "\n",
    "**[text about the topic goes here.]**\n",
    "\n",
    "<a id=\"intro_sub1\"></a>\n",
    "## [Subsection 1]\n",
    "**[Text about optional subsections.]**\n",
    "\n",
    "<a href=\"#top\">Return to the Table of Contents</a>\n",
    "\n",
    "<a id=\"requirements\"></a>\n",
    "## Notebook Requirements\n",
    "* [Python 2.7.3](https://www.python.org/download/releases/2.7/)\n",
    "* [Numpy 1.9](http://www.numpy.org)\n",
    "* [Qiime 1.9](https://www.qiime.org/install/install.html)\n",
    "* [hdf5](http://www.hdfgroup.org/HDF5/) and [h5py](http://www.h5py.org). This is required to read the American Gut biom tables in Qiime.\n",
    "* [Jinja2](http://jinja.pocoo.org/docs/dev/), [pyzmq](https://learning-0mq-with-pyzmq.readthedocs.org/en/latest/) and  [tornado](http://www.tornadoweb.org/en/stable/). These are required to open a local IPython notebook instance. hese are required to open a local ipython notebook on your machine. They are not automatically installed with iPython or Qiime.\n",
    "* [Statsmodels 0.6.0](http://statsmodels.sourceforge.net)\n",
    "* [American Gut Python Library](https://github.com/biocore/American-Gut)\n",
    "* $\\LaTeX$. [LiveTex](http://www.tug.org/texlive/) offers one installation solution.\n",
    "\n",
    "<a id=\"top\"></a>\n",
    "##Table of contents\n",
    "<ul><li><a href=\"#intro\">Introduction</a>\n",
    "<ul><li><a href=\"#intro_sub1\">Subsection 1</a>\n",
    "</li></ul>\n",
    "</li><li><a href=\"#requirements\">Notebook Requirements</a>\n",
    "</li><li><a href=\"#imports\">Function Import</a>\n",
    "</li><li><a href=\"#params\">Analysis parameters</a>\n",
    "<ul><li><a href=\"#params_data\">Dataset Selection</a>\n",
    "</li><li><a href=\"#params_save\">File Saving Parameters</a>\n",
    "</li><li><a href=\"#params_text\">Text File and Metadata Parameters</a>\n",
    "</li><li><a href=\"#params_cat\">Analysis Category Parameters</a>\n",
    "</li><li><a href=\"#params_alpha\">Alpha Diversity Parameters</a>\n",
    "</li><li><a href=\"#params_beta\">Beta Diversity Parameters</a>\n",
    "</li><li><a href=\"#params_gs\">Group Significance Parameters</a>\n",
    "</li><li><a href=\"#params_figs\">Plotting Parameters</a>\n",
    "</li></ul>\n",
    "</li><li><a href=\"#dir\">Files and Directories</a>\n",
    "<ul><li><a href=\"#dir_base\">Base Directory</a>\n",
    "</li><li><a href=\"#dir_data\">Sample Directory and Files</a>\n",
    "</li><li><a href=\"#dir_bdiv\">Beta Diversity Analsysis Directories and Files</a>\n",
    "</li><li><a href=\"#dir_gs\">Group Significance Analysis Directories and Files</a>\n",
    "</li><li><a href=\"#dir_image\">Image Directories and Files</a>\n",
    "</li></ul>\n",
    "</li><li><a href=\"#download\">Data Download</a>\n",
    "</li><li><a href=\"#alpha\">Alpha Diversity</a>\n",
    "</li><li><a href=\"#beta\">Beta Diversity</a>\n",
    "</li><li><a href=\"#group\">Group Significance</a>\n",
    "</li><li><a href=\"#discussion\">Discussion</a>\n",
    "</li><li><a href=\"#refs\">References</a>\n",
    "</li></ul>\n",
    "\n",
    "<a id=\"imports\"></a>\n",
    "## Function Import\n",
    "We start by importing necessary functions, and determining if files should be overwritten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "import scipy\n",
    "import skbio\n",
    "import biom\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import statsmodels.api as sms\n",
    "import statsmodels.formula.api as smf\n",
    "import americangut.diversity_analysis as div\n",
    "\n",
    "from matplotlib import rcParams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also set up some plotting parameters so the generated figures use Helvetica or Arial as their default font. For more on font properties, see the matplotlib documentation on [text objects](http://matplotlib.org/api/text_api.html?highlight=font#matplotlib.text.Text.set_fontproperties) and [rendering text with LaTex](http://matplotlib.org/users/pgf.html?highlight=font). We will also prompt the IPython notebook to display the images we generate live in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Displays images inline\n",
    "%matplotlib inline\n",
    "\n",
    "# Sets up plotting parameters so that the default setting is use to \n",
    "# Helvetica in plots\n",
    "rcParams['font.family'] = 'sans-serif'\n",
    "rcParams['font.sans-serif'] = ['Helvetica', 'Arial']\n",
    "rcParams['text.usetex'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=#top>Return to the top</a>\n",
    "\n",
    "<a id=\"params\"></a>\n",
    "## Analysis Parameters\n",
    "We can also set some necessary parameters for handling files and this analysis. It’s easier to set them as a block, here, so that our systems are consistent than to modify each of the variables later in the import if our needs or our data changes.\n",
    "\n",
    "<a id=\"params_data\"></a>\n",
    "### Dataset Selection\n",
    "We will start by selecting which dataset we’d like to use for this analysis. We can select to work with the full OTU table or focus on a single body site. We can also choose which grouping of this data we’d like to use, limiting the analysis to a certain subset of the American Gut Population.\n",
    "\n",
    "<table style=\"width:90%;\n",
    "              border-style:hidden;\n",
    "              borders-collapse:collapse;\n",
    "              line-height:120%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 30%;\n",
    "                   text-align:left; \n",
    "                   vertical-align:top;\n",
    "                   background-color:#D0D0D0;\n",
    "                   border-right:hidden; \n",
    "                   border-bottom: 10px solid white;\n",
    "                   padding:10px\">\n",
    "            <strong>site</strong><br>\n",
    "(<code style=\"color:Firebrick;background-color:#D0D0D0\">\"all\"</code>, \n",
    "<code style=\"color:Firebrick;background-color:#D0D0D0\">\"fecal\"</code>, \n",
    "<code style=\"color:Firebrick;background-color:#D0D0D0\">\"oral\"</code>, \n",
    "<code style=\"color:Firebrick;background-color:#D0D0D0\">\"skin\"</code>)\n",
    "        </td>\n",
    "        <td style=\"width: 60%\n",
    "                   text-align: left;\n",
    "                   vertical-align: top;\n",
    "                   border-left:hidden;\n",
    "                   border-top:hidden;\n",
    "                   border-bottom:hidden;\n",
    "                   padding:10px;\n",
    "                   \">\n",
    "            This identifies the bodysite where the analysis should be analyzed. It is recommended that categorical analysis focus on a single bodysite, since location on the human body has the largest effect on the microbial communities at those sites in relatively healthy adults and children four years of age and older [<a href=\"#22699611\">22699611</a>; <a href=\"#22699609\">22699609</a>].\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"width: 30%;\n",
    "                   text-align:left; \n",
    "                   vertical-align:top;\n",
    "                   background-color:#D0D0D0;\n",
    "                   border-right:hidden; \n",
    "                   border-bottom: 10px solid white;\n",
    "                   padding:10px\">\n",
    "            <strong>dataset</strong><br>(\n",
    "            <code style=\"color:Firebrick;background-color:#D0D0D0\">\"\"</code>,\n",
    "            <code style=\"color:Firebrick;background-color:#D0D0D0\">\"all_participants_all_samples\"</code>,\n",
    "            <code style=\"color:Firebrick;background-color:#D0D0D0\">\"all_participants_one_sample\"</code>,\n",
    "            <code style=\"color:Firebrick;background-color:#D0D0D0\">\"sub_participants_all_samples\"</code>,\n",
    "            <code style=\"color:Firebrick;background-color:#D0D0D0\">\"sub_participants_one_sample\"</code>)\n",
    "        </td>\n",
    "        <td style=\"width: 60%\n",
    "                   text-align: left;\n",
    "                   vertical-align: top;\n",
    "                   border-left:hidden;\n",
    "                   border-top:hidden;\n",
    "                   border-bottom:hidden;\n",
    "                   padding:10px;\n",
    "                   \">\n",
    "            <p><strong><code>dataset</code></strong> identifies the subset of samples to be used \n",
    "            for analysis.</p> \n",
    "            <p>If the <strong><code>site</code></strong> is <code><font color=\"Firebrick\">\"all\"</font></code>, the <strong><code>dataset</code></strong> should be <code><font color=\"Firebrick\">\"\"</font></code>. <br>\n",
    "            There are not multiple subsets of samples avaliable for all data, if data was generated \n",
    "            through the preprocessing notebook.</p>\n",
    "            <p>For site-specific analyses, every site has data for all participants and all \n",
    "            samples.\n",
    "            Each individual’s microbiome is correlated with itself \n",
    "            [<a href=\"#21624126\">21624126</a>, <a href=\"#21885731\">21885731</a>], so to allow \n",
    "            multiple samples per individual violates an assumption of independence used in many statistical tests. Therefore, the \n",
    "            Preprocessing Notebook draws a single sample for each individual at each bodysite.</p>\n",
    "            <p>We may also choose to work with a subset of the data. The preprocessing notebook \n",
    "            selects a healthy subset of adult participants. This includes individuals between 20 \n",
    "            and 70 who have a BMI between 18.5 and 30. Additionally, these individuals cannot have \n",
    "            been diagnosed with IBD or diabetes and do not report using antibiotics in the past\n",
    "            year.</p>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "site = 'fecal'\n",
    "dataset = 'all_participants_one_sample'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"params_save\"></a>\n",
    "### File Saving Parameters\n",
    "\n",
    "In the course of this analysis, a series of files can be generated. The File Saving Parameters determine if new files are saved.\n",
    "\n",
    "<table style=\"width:90%;\n",
    "              border-style:hidden;\n",
    "              borders-collapse:collapse;\n",
    "              line-height:120%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 30%;\n",
    "                   text-align:left; \n",
    "                   vertical-align:top;\n",
    "                   background-color:#D0D0D0;\n",
    "                   border-right:hidden; \n",
    "                   border-bottom: 10px solid white;\n",
    "                   padding:10px\">\n",
    "            <strong>overwrite</strong><br />(boolian)\n",
    "        </td>\n",
    "        <td style=\"width: 60%\n",
    "                   text-align: left;\n",
    "                   vertical-align: top;\n",
    "                   border-left:hidden;\n",
    "                   border-top:hidden;\n",
    "                   border-bottom:hidden;\n",
    "                   padding:10px;\n",
    "                   \">\n",
    "            <p>When <strong><code>overwrite</code></strong> is \n",
    "            <code><font color=\"228B22\">True</font></code>, new files will\n",
    "            be generated and saved during data processing. <br>It is \n",
    "            recommended that overwrite be set to \n",
    "            <code><font color=\"228B22\">False</font></code>, in which case \n",
    "            new files will only be generated when the file does not exist. \n",
    "            This substantially decreases analysis time.</p>\n",
    "            <p><strong><code>overwrite</code></strong> will also cause the \n",
    "            notebook to generate new post-hoc beta diversity comparisons, \n",
    "            even if the files exist. This can be computationally \n",
    "            expensive, and scales with the number of groups in a metadata \n",
    "            category and the number of samples.</p>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"width: 30%;\n",
    "                   text-align:left; \n",
    "                   vertical-align:top;\n",
    "                   background-color:#D0D0D0;\n",
    "                   border-right:hidden; \n",
    "                   border-bottom: 10px solid white;\n",
    "                   padding:10px\">\n",
    "            <strong>save_images</strong><br>(boolian)\n",
    "        </td>\n",
    "        <td style=\"width: 60%\n",
    "                   text-align: left;\n",
    "                   vertical-align: top;\n",
    "                   border-left:hidden;\n",
    "                   border-top:hidden;\n",
    "                   border-bottom:hidden;\n",
    "                   padding:10px;\n",
    "                   \">\n",
    "            This notebook will generate images of the power curves. By \n",
    "            default, these will be displayed inside the notebook. However, \n",
    "            some users also find it advantageous to save the images.\n",
    "            The file format can be set with the \n",
    "            <a href=\"#dir_analysis\"><strong><code>image_pattern</code></strong></a>.\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "overwrite = False\n",
    "save_images = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Return to the top</a>\n",
    "\n",
    "<a id=\"params_text\"></a>\n",
    "### Text File and Metadata Parameters\n",
    "Qiime-formatted metadata and results files are frequently tab-separated text (.txt) files. These files can be opened in Excel or spreadsheet programs. You can learn more about Qiime mapping files [here](http://qiime.org/documentation/file_formats.html). We use the Pandas library to read most of our text files, which provides some spreadsheet like functionalities.\n",
    "\n",
    "<table style=\"width:90%;\n",
    "              border-style:hidden;\n",
    "              borders-collapse:collapse;\n",
    "              line-height:120%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 30%;\n",
    "                   text-align:left; \n",
    "                   vertical-align:top;\n",
    "                   background-color:#D0D0D0;\n",
    "                   border-right:hidden; \n",
    "                   border-bottom: 10px solid white;\n",
    "                   padding:10px\">\n",
    "            <strong>txt_delim</strong><br />(string)\n",
    "        </td>\n",
    "        <td style=\"width: 60%\n",
    "                   text-align: left;\n",
    "                   vertical-align: top;\n",
    "                   border-left:hidden;\n",
    "                   border-top:hidden;\n",
    "                   border-bottom:hidden;\n",
    "                   padding:10px;\n",
    "                   \">\n",
    "            <strong><code>txt_delim</code></strong> specifies the way columns are separated in the files. Qiime typically consumes and produces tab-delimited (<code><font color=\"FireBrick\">\"\\t\"</font></code>) text files (.txt) for metadata and results generation.\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"width: 30%;\n",
    "                   text-align:left; \n",
    "                   vertical-align:top;\n",
    "                   background-color:#D0D0D0;\n",
    "                   border-right:hidden; \n",
    "                   border-bottom: 10px solid white;\n",
    "                   padding:10px\">\n",
    "              <strong>map_index</strong><br />(string)\n",
    "        </td>\n",
    "        <td style=\"width: 60%\n",
    "                   text-align: left;\n",
    "                   vertical-align: top;\n",
    "                   border-left:hidden;\n",
    "                   border-top:hidden;\n",
    "                   border-bottom:hidden;\n",
    "                   padding:10px;\n",
    "                   \">\n",
    "            The name of the column containg the sample names. In Qiime, this column is called <code><font color=\"FireBrick\">#SampleID</font></code>.\n",
    "        </td>\n",
    "    <tr>\n",
    "\n",
    "    <tr>\n",
    "        <td style=\"width: 30%;\n",
    "                   text-align:left; \n",
    "                   vertical-align:top;\n",
    "                   background-color:#D0D0D0;\n",
    "                   border-right:hidden; \n",
    "                   border-bottom: 10px solid white;\n",
    "                   padding:10px\">\n",
    "            <strong>map_nas</strong><br />(list of strings)\n",
    "        </td>\n",
    "        <td style=\"width: 60%\n",
    "                   text-align: left;\n",
    "                   vertical-align: top;\n",
    "                   border-left:hidden;\n",
    "                   border-top:hidden;\n",
    "                   border-bottom:hidden;\n",
    "                   padding:10px;\n",
    "                   \">\n",
    "            t is possible a mapping file map be missing values, since American Gut participants are free to skip any question. The pandas package is able to omit these missing samples from analysis. In raw American Gut files, missing values are typically denoted as <code><font color=\"FireBrick\">“NA”</font></code>, <code><font color=\"FireBrick\">“no_data”</font></code>, <code><font color=\"FireBrick\">“unknown”</font></code>, and empty spaces (<code><font color=\"FireBrick\">“”</font></code>).\n",
    "        </td>\n",
    "    <tr>\n",
    "\n",
    "    <tr>\n",
    "        <td style=\"width: 30%;\n",
    "                   text-align:left; \n",
    "                   vertical-align:top;\n",
    "                   background-color:#D0D0D0;\n",
    "                   border-right:hidden; \n",
    "                   border-bottom: 10px solid white;\n",
    "                   padding:10px\">\n",
    "            <strong>write_na</strong><br /> (string)\n",
    "        </td>\n",
    "        <td style=\"width: 60%\n",
    "                   text-align: left;\n",
    "                   vertical-align: top;\n",
    "                   border-left:hidden;\n",
    "                   border-top:hidden;\n",
    "                   border-bottom:hidden;\n",
    "                   padding:10px;\n",
    "                   \">\n",
    "            The value to denote missing values when text files are written from Pandas data frames. Using an empty space, (<code><font color=\"FireBrick\">“”</font></code>) will allow certain Qiime scripts, like [group_signigance.py](http://qiime.org/scripts/group_significance.html), to ignore the missing values.\n",
    "        </td>\n",
    "    <tr>\n",
    "\n",
    "    <tr>\n",
    "        <td style=\"width: 30%;\n",
    "                   text-align:left; \n",
    "                   vertical-align:top;\n",
    "                   background-color:#D0D0D0;\n",
    "                   border-right:hidden; \n",
    "                   border-bottom: 10px solid white;\n",
    "                   padding:10px\">\n",
    "            <strong>date_cols</strong><br /> (list of strings)\n",
    "        </td>\n",
    "        <td style=\"width: 60%\n",
    "                   text-align: left;\n",
    "                   vertical-align: top;\n",
    "                   border-left:hidden;\n",
    "                   border-top:hidden;\n",
    "                   border-bottom:hidden;\n",
    "                   padding:10px;\n",
    "                   \">\n",
    "            Temporal data can be identified using the <strong><code>date_cols</code></strong>, allowing the Pandas program to do time-based analysis. In the American Gut dataset, there are four we identify initially: \n",
    "            <ul><li>*BIRTH_DATE*          (the participant’s birthdate)\n",
    "            </li><li>*COLLECTION_DATE*    (the day the sample was collected)\n",
    "            </li><li>*SAMPLE_TIME*        (the time the sample was collected)\n",
    "            </li><li>*RUN_DATE*           (the day the samples were sequenced)\n",
    "            </li></ul>\n",
    "        </td>\n",
    "    <tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sets parameters for file handling and reading tables\n",
    "# into pandas\n",
    "txt_delim = '\\t'\n",
    "map_index = '#SampleID'\n",
    "map_nas = ['NA', 'no_data', 'unknown', '']\n",
    "write_na = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Return to the top</a>\n",
    "\n",
    "<a id=\"params_alpha\"></a>\n",
    "### Alpha Diversity Parameters\n",
    "\n",
    "<p>This notebook will compare alpha diversity and beta diversity for the category selected.  Alpha diversity is a comparison of intra-community variation. When alpha diversity values are compared, the comparison does not take into account the community structure. So, two communities which share no species can have the same alpha diversity. American Gut Analyses primarily focus on an alpha diversity metric called PD Whole Tree Diversity [<a herf=\"#15831718\">15831718</a>]. PD Whole Tree is phylogenetically aware, meaning that it takes into account shared evolutionary history.</p>\n",
    "<p>We will compare alpha diversity using a [kruskall-wallis test](http://en.wikipedia.org/wiki/Kruskal–Wallis_one-way_analysis_of_variance), and we will plot the results as a [boxplot](http://en.wikipedia.org/wiki/Box_plot). We can set parameters for the way we make the comparison and how the figure will look.</p>\n",
    "\n",
    "\n",
    "<table style=\"width:90%;\n",
    "              border-style:hidden;\n",
    "              borders-collapse:collapse;\n",
    "              line-height:120%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 30%;\n",
    "                   text-align:left; \n",
    "                   vertical-align:top;\n",
    "                   background-color:#D0D0D0;\n",
    "                   border-right:hidden; \n",
    "                   border-bottom: 10px solid white;\n",
    "                   padding:10px\">\n",
    "            <strong>a_div_metric</strong><br />(string)\n",
    "        </td>\n",
    "        <td style=\"width: 60%\n",
    "                   text-align: left;\n",
    "                   vertical-align: top;\n",
    "                   border-left:hidden;\n",
    "                   border-top:hidden;\n",
    "                   border-bottom:hidden;\n",
    "                   padding:10px;\n",
    "                   \">\n",
    "            <p>The alpha diversity metric to be used in the analysis. Mapping files generated by the Preprocessing Notebook have a set of mapping columns appended which provide the mean for several metrics. These are labeled as the metric name with <font color=\"firebrick\"><code>“_mean”</code></font> appended to the end, to indicate the values are the mean of 10 rarefactions.</p>\n",
    "<p>There are multiple alpha diversity metrics which can be used. The preprocessing notebook calculates four possible alpha diversity metrics for the data (PD Whole Tree Diversity [<a href=\"#15831718\">15831718</a>], Shannon Diversity [<a href=\"#shannon\">Shannon</a>], Chao1 diversity [<a href=\"#chao1\">Chao</a>], and Observed Species diversity). The default value used here, <code><font color=\"Firebrick\">“PD_whole_tree_mean”</font></code>, is the only metric which takes into account the evolutionary relationship between organisms in a sample.</p>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"width: 30%;\n",
    "                   text-align:left; \n",
    "                   vertical-align:top;\n",
    "                   background-color:#D0D0D0;\n",
    "                   border-right:hidden; \n",
    "                   border-bottom: 10px solid white;\n",
    "                   padding:10px\">\n",
    "            <strong>a_ylabel</strong><br />(string)\n",
    "        </td>\n",
    "        <td style=\"width: 60%\n",
    "                   text-align: left;\n",
    "                   vertical-align: top;\n",
    "                   border-left:hidden;\n",
    "                   border-top:hidden;\n",
    "                   border-bottom:hidden;\n",
    "                   padding:10px;\n",
    "                   \">\n",
    "            This y-label appears on the boxplot to help clarify the information presented there. Alpha diversity is a unitless quantity.\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"width: 30%;\n",
    "                   text-align:left; \n",
    "                   vertical-align:top;\n",
    "                   background-color:#D0D0D0;\n",
    "                   border-right:hidden; \n",
    "                   border-bottom: 10px solid white;\n",
    "                   padding:10px\">\n",
    "            <strong>a_ylim</strong><br />(2 element list of numbers)\n",
    "        </td>\n",
    "        <td style=\"width: 60%\n",
    "                   text-align: left;\n",
    "                   vertical-align: top;\n",
    "                   border-left:hidden;\n",
    "                   border-top:hidden;\n",
    "                   border-bottom:hidden;\n",
    "                   padding:10px;\n",
    "                   \">\n",
    "            This specifies the limits for the y axis. Limits should be set as a function of the diversity metric. With PD whole tree diversity, limits of <code>[5, 55]</code> is suggested. For shannon diversity, <code>[0, 8]</code> should be used as limits. Chao1 diversity has a larger range, and <code>[100, 1000]</code> can be used as limits. Observed Species also has a larger range, and <code>[0, 800]</code> may be an appropriate starting place.\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Alpha Diversity Parameters\n",
    "a_div_metric = 'PD_whole_tree_mean'\n",
    "a_ylabel = 'PD Whole Tree Mean'\n",
    "a_ylim = [5, 55]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Return to the top</a>\n",
    "\n",
    "<a id=\"params_beta\"></a>\n",
    "## Beta Diversity Parameters\n",
    "\n",
    "Beta diversity looks at the difference in community structure across two communities. Each metric calculates a distance between the communities, which is reflective of their difference. American Gut Analyses have calculated weighted and unweighted UniFrac distance for the communities [<a href=\"#16332807\">16332807</a>]. UniFrac distance takes into account the evolutionary relationship between samples, by determining what fraction of evolutionary history is different between two samples. Weighted UniFrac also takes into account the relative abundance of each taxa, while unweighted UniFrac distance only considers presence and absence. We will compare intra and intergroup UniFrac distances using permutation tests. We will plot the distance between samples as a bar chart. \n",
    "\n",
    "<table style=\"width:90%;\n",
    "              border-style:hidden;\n",
    "              borders-collapse:collapse;\n",
    "              line-height:120%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 30%;\n",
    "                   text-align:left; \n",
    "                   vertical-align:top;\n",
    "                   background-color:#D0D0D0;\n",
    "                   border-right:hidden; \n",
    "                   border-bottom: 10px solid white;\n",
    "                   padding:10px\">\n",
    "            <strong>b_div_metric</strong><br />(string)\n",
    "        </td>\n",
    "        <td style=\"width: 60%\n",
    "                   text-align: left;\n",
    "                   vertical-align: top;\n",
    "                   border-left:hidden;\n",
    "                   border-top:hidden;\n",
    "                   border-bottom:hidden;\n",
    "                   padding:10px;\n",
    "                   \">\n",
    "            The beta diversity metric to be used in the analysis. This name will appear at the beginning of the distance matrix file.\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Beta Diversity Parameters\n",
    "b_div_metric = 'unweighted_unifrac'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Parameters\n",
    "\n",
    "We'll start by setting up the parameters for our regression and providing several peices of information about the variables we'll be working with. [More text to be added laters...]\n",
    "\n",
    "<table style=\"width:90%;\n",
    "              border-style:hidden;\n",
    "              borders-collapse:collapse;\n",
    "              line-height:120%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 30%;\n",
    "                   text-align:left; \n",
    "                   vertical-align:top;\n",
    "                   background-color:#D0D0D0;\n",
    "                   border-right:hidden; \n",
    "                   border-bottom: 10px solid white;\n",
    "                   padding:10px\">\n",
    "            <strong>all_variables</strong><br />(string)\n",
    "        </td>\n",
    "        <td style=\"width: 60%\n",
    "                   text-align: left;\n",
    "                   vertical-align: top;\n",
    "                   border-left:hidden;\n",
    "                   border-top:hidden;\n",
    "                   border-bottom:hidden;\n",
    "                   padding:10px;\n",
    "                   \">\n",
    "            The names of any variables which will be used in the regression.\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"width: 30%;\n",
    "                   text-align:left; \n",
    "                   vertical-align:top;\n",
    "                   background-color:#D0D0D0;\n",
    "                   border-right:hidden; \n",
    "                   border-bottom: 10px solid white;\n",
    "                   padding:10px\">\n",
    "            <strong>continous_variables</strong><br />(string)\n",
    "        </td>\n",
    "        <td style=\"width: 60%\n",
    "                   text-align: left;\n",
    "                   vertical-align: top;\n",
    "                   border-left:hidden;\n",
    "                   border-top:hidden;\n",
    "                   border-bottom:hidden;\n",
    "                   padding:10px;\n",
    "                   \">\n",
    "            The names of any variables which will be used in the regression.\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_variables = ['AGE', 'BMI', 'IBD', 'DIABETES', 'ANTIBIOTIC_SELECT', \n",
    "                 'ALCOHOL_FREQUENCY', 'TYPES_OF_PLANTS', 'COLLECTION_MONTH',\n",
    "                 'EXERCISE_FREQUENCY', 'EXERCISE_LOCATION', 'SLEEP_DURATION',\n",
    "                 'PD_whole_tree_mean', 'SEX', 'BMI_CAT']\n",
    "response = 'PD_whole_tree_mean'\n",
    "\n",
    "con_predictors = ['AGE', 'BMI']\n",
    "\n",
    "cat_predictors = ['IBD', 'DIABETES', 'ANTIBIOTIC_SELECT', \n",
    "                  'ALCOHOL_FREQUENCY', 'TYPES_OF_PLANTS', 'COLLECTION_MONTH',\n",
    "                  'EXERCISE_FREQUENCY', 'EXERCISE_LOCATION', 'SLEEP_DURATION',\n",
    "                  'SEX', 'BMI_CAT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define our own categorization functions, rather than using the Patsy coding system, so we can pick our own reference varaibles. We are doing this in lou of using the [Patsy coding system](http://statsmodels.sourceforge.net/devel/contrasts.html), which is another option for handling categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def categorize_ibd(x):\n",
    "    if x == 'I do not have IBD':\n",
    "        return 0\n",
    "    elif x in {\"Ulcerative colitis\", \"Crohn's disease\"}:\n",
    "        return 1\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def categorize_diabetes(x):\n",
    "    if x == 'I do not have diabetes':\n",
    "        return 0\n",
    "    elif x in {'Type I', 'Type II'}:\n",
    "        return 1\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def categorize_antibiotics(x):\n",
    "    if x == 'Not in the last year':\n",
    "        return np.array([0, 0, 0])\n",
    "    elif x in {'In the past week', 'In the past month'}:\n",
    "        return np.array([1, 0, 0])\n",
    "    elif x == 'In the past 6 months':\n",
    "        return np.array([0, 1, 0])\n",
    "    elif x == 'In the past year':\n",
    "        return np.array([0, 0, 1])\n",
    "    else:\n",
    "        return np.array([np.nan]*3)\n",
    "    \n",
    "def categorize_frequency(x):\n",
    "    if x == 'Never':\n",
    "        return np.array([0, 0, 0, 0])\n",
    "    elif x in {'Rarely', 'Rarely (few times/month)'}:\n",
    "        return np.array([1, 0, 0, 0])\n",
    "    elif x in {'Occasionally', 'Occasionally (1-2 times/week)'}:\n",
    "        return np.array([0, 1, 0, 0])\n",
    "    elif x in {'Regularly', 'Regularly (3-5 times/week)'}:\n",
    "        return np.array([0, 0, 1, 0])\n",
    "    elif x == 'Daily':\n",
    "        return np.array([0, 0, 0, 1])\n",
    "    else:\n",
    "        return np.array([np.nan]*4)\n",
    "\n",
    "def categorize_plants(x):\n",
    "    if x == 'Less than 5':\n",
    "        return np.array([0, 0, 0, 0])\n",
    "    elif x == '6 to 10':\n",
    "        return np.array([1, 0, 0, 0])\n",
    "    elif x == '11 to 20':\n",
    "        return np.array([0, 1, 0, 0])\n",
    "    elif x in {'28', '21 to 30'}:\n",
    "        return np.array([0, 0, 1, 0])\n",
    "    elif x == 'More than 30':\n",
    "        return np.array([0, 0, 0, 1])\n",
    "    else:\n",
    "        return np.array([np.nan]*4)\n",
    "    \n",
    "\n",
    "def descritize_month(x):\n",
    "    try:\n",
    "        t = time.strptime(x, '%B')\n",
    "        return t.tm_mon\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "def categorize_season(x):\n",
    "    if x == 'Winter':\n",
    "        return np.array([0, 0, 0])\n",
    "    elif x == 'Spring':\n",
    "        return np.array([1, 0, 0])\n",
    "    elif x == 'Summer':\n",
    "        return np.array([0, 1, 0])\n",
    "    elif x == 'Fall':\n",
    "        return np.array([0, 0, 1])\n",
    "    else:\n",
    "        return np.array([np.nan]*3)\n",
    "    \n",
    "def descritize_season(x):\n",
    "    if x == \"Winter\":\n",
    "        return 0\n",
    "    elif x == 'Spring':\n",
    "        return 1\n",
    "    elif x == 'Summer':\n",
    "        return 2\n",
    "    elif x == 'Fall':\n",
    "        return 3\n",
    "    \n",
    "def categorize_location(x):\n",
    "    if x == 'Indoors':\n",
    "        return np.array([0, 0, 0, 0])\n",
    "    elif x == 'Outdoors':\n",
    "        return np.array([1, 0, 0, 0])\n",
    "    elif x == 'Depends on the Season':\n",
    "        return np.array([0, 1, 0, 0])\n",
    "    elif x == 'Both':\n",
    "        return np.array([0, 0, 1, 0])\n",
    "    elif x == 'None of the above':\n",
    "        return np.array([0, 0, 0, 1])\n",
    "    else:\n",
    "        return np.array([np.nan]*4)\n",
    "\n",
    "def categorize_sleep(x):\n",
    "    if x == 'Less than 6 hours':\n",
    "        return np.array([0, 0, 0])\n",
    "    elif x == '6-7 hours':\n",
    "        return np.array([1, 0, 0])\n",
    "    elif x == '7-8 hours':\n",
    "        return np.array([0, 1, 0])\n",
    "    elif x == '8 or more hours':\n",
    "        return np.array([0, 0, 1])\n",
    "    else:\n",
    "        return np.array([np.nan]*3)\n",
    "    \n",
    "def categorize_sex(x):\n",
    "    if x == 'female':\n",
    "        return np.array([0, 0])\n",
    "    elif x == 'male':\n",
    "        return np.array([1, 0])\n",
    "    elif x == 'other':\n",
    "        return np.array([0, 1])\n",
    "    else:\n",
    "        return np.array([np.nan, np.nan])\n",
    "\n",
    "def categorize_bmi(x):\n",
    "    if x == 'Normal':\n",
    "        return np.array([0, 0, 0])\n",
    "    elif x == \"Underweight\":\n",
    "        return np.array([1, 0, 0])\n",
    "    elif x == 'Overweight':\n",
    "        return np.array([0, 1, 0])\n",
    "    elif x == 'Obese':\n",
    "        return np.array([0, 0, 1])\n",
    "    else:\n",
    "        return np.array([np.nan]*3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll create a dictory of categorical variables, mapping the variable to its conversion function and the column names when converted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conversion = {'IBD': (['ibd_case'], categorize_ibd),\n",
    "              'DIABETES': (['diabetes_case'], categorize_diabetes),\n",
    "              'ANTIBIOTIC_SELECT': (['ABX_past_month', 'ABX_past_6_months', 'ABX_past_year'], categorize_antibiotics),\n",
    "              'TYPES_OF_PLANTS': (['PLANTS_6_10', 'PLANTS_11_20', 'PLANTS_21_30', 'PLANTS_30+'], categorize_plants),\n",
    "              'EXERCISE_LOCATION': (['EX_LOC_out', 'EX_LOC_depends', 'EX_LOC_both', 'EX_LOC_none'], categorize_location),\n",
    "              'SLEEP_DURATION': (['SLEEP_6', 'SLEEP_7', 'SLEEP_8'], categorize_sleep),\n",
    "              'SEX': (['SEX_m', 'SEX_o'], categorize_sex),\n",
    "              'BMI_CAT': (['BMI_under', 'BMI_over', 'BMI_obese'], categorize_bmi),\n",
    "              'COLLECTION_MONTH': (['COLLECTION_MONTH'], descritize_month),\n",
    "              'EXERCISE_FREQUENCY': (['EX_FREQ_rare', 'EX_FREQ_occ', 'EX_FREQ_regular', 'EX_FREQ_daily'], categorize_frequency),\n",
    "              'ALCOHOL_FREQUENCY': (['ETOH_FREQ_rare', 'ETOH_FREQ_occ', 'ETOH_regular', 'ETOH_FREQ_daily'], categorize_frequency)\n",
    "              }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Return to the top</a>\n",
    "\n",
    "<a id=\"dir\"></a>\n",
    "## Files and Directories\n",
    "\n",
    "We need to import working OUT data for analysis and set up a location where results from our analysis can be saved. This notebook consumes pre-processed tables (OTU tables, mapping files and distance matrices) produced by the Preprocessing Notebook. These can be downloaded individually, or the whole set is available [here](https://www.dropbox.com/s/q7wrf4tme2mrt0p/all_samples.tgz).\n",
    "\n",
    "As we set up directories, we’ll make use the of the **check_dir** function. This will create the directories we identify if they do not exist.\n",
    "\n",
    "<a id=\"dir_base\"></a>\n",
    "\n",
    "### Base Directory\n",
    "\n",
    "We need a general location to do all our analysis; this is the base_dir. All our other directories will exist within the **$base_dir$**, and allow us to work. The working directory is a directory within the base directory where we’ll find the files we need.\n",
    "\n",
    "<table style=\"width:90%;\n",
    "              border-style:hidden;\n",
    "              borders-collapse:collapse;\n",
    "              line-height:120%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 30%;\n",
    "                   text-align:left; \n",
    "                   vertical-align:top;\n",
    "                   background-color:#D0D0D0;\n",
    "                   border-right:hidden; \n",
    "                   border-bottom: 10px solid white;\n",
    "                   padding:10px\">\n",
    "            <strong>base_dir</strong><br />(string)\n",
    "        </td>\n",
    "        <td style=\"width: 60%\n",
    "                   text-align: left;\n",
    "                   vertical-align: top;\n",
    "                   border-left:hidden;\n",
    "                   border-top:hidden;\n",
    "                   border-bottom:hidden;\n",
    "                   padding:10px;\n",
    "                   \">\n",
    "            The filepath for the directory where any files associated with the analysis should be saved. It is suggested this be a directory called <strong>agp_analysis</strong>, and be located in the same directory as the IPython notebooks.\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"width: 30%;\n",
    "                   text-align:left; \n",
    "                   vertical-align:top;\n",
    "                   background-color:#D0D0D0;\n",
    "                   border-right:hidden; \n",
    "                   border-bottom: 10px solid white;\n",
    "                   padding:10px\">\n",
    "            <strong>working_dir</strong><br />(string)\n",
    "        </td>\n",
    "        <td style=\"width: 60%\n",
    "                   text-align: left;\n",
    "                   vertical-align: top;\n",
    "                   border-left:hidden;\n",
    "                   border-top:hidden;\n",
    "                   border-bottom:hidden;\n",
    "                   padding:10px;\n",
    "                   \">\n",
    "            The file path for the directory where all data files associated with this analysis have been stored. This should contain the results of the Preprocessing Notebook.<br>\n",
    "The working_dir is expected to be a directory called <strong>sample_data</strong> in the <strong><code>base_dir</code></strong>.\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"width: 30%;\n",
    "                   text-align:left; \n",
    "                   vertical-align:top;\n",
    "                   background-color:#D0D0D0;\n",
    "                   border-right:hidden; \n",
    "                   border-bottom: 10px solid white;\n",
    "                   padding:10px\">\n",
    "            <strong>analysis_dir</strong><br />(string)\n",
    "        </td>\n",
    "        <td style=\"width: 60%\n",
    "                   text-align: left;\n",
    "                   vertical-align: top;\n",
    "                   border-left:hidden;\n",
    "                   border-top:hidden;\n",
    "                   border-bottom:hidden;\n",
    "                   padding:10px;\n",
    "                   \">\n",
    "            The file path where analysis results should be stored. This is expected to be a folder in the <strong><code>base_dir</code></strong>.\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sets up the base directory\n",
    "# base_dir = os.path.join(os.path.abspath('.'), 'agp_analysis')\n",
    "base_dir = '/Users/jwdebelius/Desktop/agp_analysis'\n",
    "div.check_dir(base_dir)\n",
    "\n",
    "# Sets up data directory\n",
    "working_dir = os.path.join(base_dir, 'sample_data')\n",
    "div.check_dir(working_dir)\n",
    "\n",
    "# Sets up the analysis directory\n",
    "analysis_dir = os.path.join(base_dir, 'analysis_results')\n",
    "div.check_dir(analysis_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Return to the top</a>\n",
    "<a id=\"dir_data\"></a>\n",
    "### Sample Directory and Files\n",
    "\n",
    "We’ll focus our analysis on fecal samples, which we set with the <a href=\"#params_data\"><strong><code>site</code></strong></a> variable. We’ve chosen to focus on a single sample from a healthy subset of adults in the American Gut population (set with the <strong><code><a href=\"#params_data\">dataset</a></code></strong> variable). To be included in this group, a sample must come from a donor between the ages of 20 and 69 (inclusive) who has a BMI between 18.5 and 30 and does not report having IBD or diabetes.  \n",
    "Our analysis will use a mapping file, OTU table and unweighted UniFrac distance matrix.\n",
    "\n",
    "<table style=\"width:90%;\n",
    "              border-style:hidden;\n",
    "              borders-collapse:collapse;\n",
    "              line-height:120%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 30%;\n",
    "                   text-align:left; \n",
    "                   vertical-align:top;\n",
    "                   background-color:#D0D0D0;\n",
    "                   border-right:hidden; \n",
    "                   border-bottom: 10px solid white;\n",
    "                   padding:10px\">\n",
    "            <strong>site_dir</strong><br>(string)\n",
    "        </td>\n",
    "        <td style=\"width: 60%\n",
    "                   text-align: left;\n",
    "                   vertical-align: top;\n",
    "                   border-left:hidden;\n",
    "                   border-top:hidden;\n",
    "                   border-bottom:hidden;\n",
    "                   padding:10px;\n",
    "                   \">\n",
    "            The filepath for the directory where data sets from fecal samples are stored. This should be a directory in the <strong><code>working_dir</code></strong>.\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"width: 30%;\n",
    "                   text-align:left; \n",
    "                   vertical-align:top;\n",
    "                   background-color:#D0D0D0;\n",
    "                   border-right:hidden; \n",
    "                   border-bottom: 10px solid white;\n",
    "                   padding:10px\">\n",
    "            <strong>data_dir</strong><br>(string)\n",
    "        </td>\n",
    "        <td style=\"width: 60%\n",
    "                   text-align: left;\n",
    "                   vertical-align: top;\n",
    "                   border-left:hidden;\n",
    "                   border-top:hidden;\n",
    "                   border-bottom:hidden;\n",
    "                   padding:10px;\n",
    "                   \">\n",
    "            The filepath of the subset participants single sample directory. This should be a folder in the <strong><code>site_dir</code></strong>.\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"width: 30%;\n",
    "                   text-align:left; \n",
    "                   vertical-align:top;\n",
    "                   background-color:#D0D0D0;\n",
    "                   border-right:hidden; \n",
    "                   border-bottom: 10px solid white;\n",
    "                   padding:10px\">\n",
    "            <strong>data_map_fp</strong><br>(string)\n",
    "        </td>\n",
    "        <td style=\"width: 60%\n",
    "                   text-align: left;\n",
    "                   vertical-align: top;\n",
    "                   border-left:hidden;\n",
    "                   border-top:hidden;\n",
    "                   border-bottom:hidden;\n",
    "                   padding:10px;\n",
    "                   \">\n",
    "            <p>This specifies the filepath for the metadata file associated with the fecal samples. This should be a text file (.txt) in the <strong><code>data_dir</code></strong>.</p>\n",
    "<p>A mapping file allows us to relate information about the sample to information about the microbiome. This contains a barcode used to identify each sample, and information about the participants from the survey, such as age, diet, or disease status. This cannot be used identify participants and does not contain data like names, physical or email addresses. In the rarefied mapping file (the filenames contain even10k), the mapping file also contains alpha diversity results for each sample. </p>\n",
    "<p>The notebook expects the metadata to be processed through the Preprocessing notebook, which involved converting continuous categories to categorical data. The rarefied file (<code>AGP_100nt_even10k…</code>), which contains alpha diversity results, is required.</p>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"width: 30%;\n",
    "                   text-align:left; \n",
    "                   vertical-align:top;\n",
    "                   background-color:#D0D0D0;\n",
    "                   border-right:hidden; \n",
    "                   border-bottom: 10px solid white;\n",
    "                   padding:10px\">\n",
    "            <strong>data_otu_fp</strong><br>(string)\n",
    "        </td>\n",
    "        <td style=\"width: 60%\n",
    "                   text-align: left;\n",
    "                   vertical-align: top;\n",
    "                   border-left:hidden;\n",
    "                   border-top:hidden;\n",
    "                   border-bottom:hidden;\n",
    "                   padding:10px;\n",
    "                   \">\n",
    "    \n",
    "<p>The filepath for the otu table file associated with the fecal samples. This should be a <a href=\"http://www.biom-format.org\">biom-format</a> file (.biom) in the <strong><code>data_dir</code></strong> [<a href=\"#23587224\">23587224</a>].</p>\n",
    "<p>The OTU table is assumed to be rarefied to an even depth. This is designated in the filename with the phrase, “even10k”, indicating the OTU table has been rarefied to 10,000 sequences per sample.</p>\n",
    "<p>An OTU table gives the bacterial counts in each sample. An OTU, or operational taxonomic unit, is technically a cluster of sequence at a certain level of similarity. We use sequence clustering to account for PCR and read error. The level of similarity used here, 97% gives approximately genus level resolution [<a href=\"#17586664\">17586664</a>]. Multiple OTUs may map to a single bacterial taxa.</p>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"width: 30%;\n",
    "                   text-align:left; \n",
    "                   vertical-align:top;\n",
    "                   background-color:#D0D0D0;\n",
    "                   border-right:hidden; \n",
    "                   border-bottom: 10px solid white;\n",
    "                   padding:10px\">\n",
    "            <strong>data_bdiv_fp</strong><br>(string)\n",
    "        </td>\n",
    "        <td style=\"width: 60%\n",
    "                   text-align: left;\n",
    "                   vertical-align: top;\n",
    "                   border-left:hidden;\n",
    "                   border-top:hidden;\n",
    "                   border-bottom:hidden;\n",
    "                   padding:10px;\n",
    "                   \">\n",
    "            <p>The filepath for the unweighted UniFrac distance matrix file associated with the fecal samples. This should be a text file (.txt) in the <strong><code>data_dir</code></strong>.</p>\n",
    "The distance matrix relates the microbiome composition in each sample community to every other community. Unweighted UniFrac distance considers shared evolutionary history and the presence or absence of OTUs in this calculation [<a href=\"#16332807\">16332807</a>]. Identical communities have a UniFrac Distance of 0, while communities which have no shared history have a UniFrac distance of 1.\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sets up OTU path directories\n",
    "site_dir = os.path.join(working_dir, site)\n",
    "div.check_dir(site_dir)\n",
    "\n",
    "data_dir = os.path.join(site_dir, dataset)\n",
    "\n",
    "# Sets the subset filepath for all samples\n",
    "data_otu_fp = os.path.join(data_dir, 'AGP_100nt_even10k_fecal.biom')\n",
    "data_map_fp = os.path.join(data_dir, 'AGP_100nt_even10k_fecal.txt')\n",
    "data_ubd_fp = os.path.join(data_dir, '%s_AGP_100nt_even10k_fecal.txt') % b_div_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Return to the top</a>\n",
    "<a id=\"dir_image\"></a>\n",
    "### Image Directories and Files\n",
    "\n",
    "We can save the graphical results of our analysis, in addition to displaying them in the notebook. We will use a file structure similar to the way we’ve saved our OTU tables to keep track of the images generated.\n",
    "\n",
    "<table style=\"width:90%;\n",
    "              border-style:hidden;\n",
    "              borders-collapse:collapse;\n",
    "              line-height:120%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 30%;\n",
    "                   text-align:left; \n",
    "                   vertical-align:top;\n",
    "                   background-color:#D0D0D0;\n",
    "                   border-right:hidden; \n",
    "                   border-bottom: 10px solid white;\n",
    "                   padding:10px\">\n",
    "            <strong>image_dir</strong><br>(string)\n",
    "        </td>\n",
    "        <td style=\"width: 60%\n",
    "                   text-align: left;\n",
    "                   vertical-align: top;\n",
    "                   border-left:hidden;\n",
    "                   border-top:hidden;\n",
    "                   border-bottom:hidden;\n",
    "                   padding:10px;\n",
    "                   \">\n",
    "            The parent directory for the images generated by the notebook. This expected to be a directory in the <strong><code>analysis_dir</code></strong>.\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"width: 30%;\n",
    "                   text-align:left; \n",
    "                   vertical-align:top;\n",
    "                   background-color:#D0D0D0;\n",
    "                   border-right:hidden; \n",
    "                   border-bottom: 10px solid white;\n",
    "                   padding:10px\">\n",
    "            <strong>site_image_dir</strong><br>(string)\n",
    "        </td>\n",
    "        <td style=\"width: 60%\n",
    "                   text-align: left;\n",
    "                   vertical-align: top;\n",
    "                   border-left:hidden;\n",
    "                   border-top:hidden;\n",
    "                   border-bottom:hidden;\n",
    "                   padding:10px;\n",
    "                   \">\n",
    "    \n",
    "A body-site specific directory for the result images. This is expected to be a directory in the <strong><code>image_dir</code></strong>.\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"width: 30%;\n",
    "                   text-align:left; \n",
    "                   vertical-align:top;\n",
    "                   background-color:#D0D0D0;\n",
    "                   border-right:hidden; \n",
    "                   border-bottom: 10px solid white;\n",
    "                   padding:10px\">\n",
    "            <strong>data_image_dir</strong><br>(string)\n",
    "        </td>\n",
    "        <td style=\"width: 60%\n",
    "                   text-align: left;\n",
    "                   vertical-align: top;\n",
    "                   border-left:hidden;\n",
    "                   border-top:hidden;\n",
    "                   border-bottom:hidden;\n",
    "                   padding:10px;\n",
    "                   \">\n",
    "            The directory for the specific dataset used in the analysis. For example, a comparison based on age could be performed on a single sample per participant among the healthy subset of adults (one_sample_sub_participants) and a single sample per participant for all participants (one_sample_all_participants) to see if the trends seen in the healthy subset hold true as the data set expands.\n",
    "This is expected to be a directory in <strong><code>image_site_dir</code></strong>.\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"width: 30%;\n",
    "                   text-align:left; \n",
    "                   vertical-align:top;\n",
    "                   background-color:#D0D0D0;\n",
    "                   border-right:hidden; \n",
    "                   border-bottom: 10px solid white;\n",
    "                   padding:10px\">\n",
    "            <strong>image_pattern</strong><br>(string)\n",
    "        </td>\n",
    "        <td style=\"width: 60%\n",
    "                   text-align: left;\n",
    "                   vertical-align: top;\n",
    "                   border-left:hidden;\n",
    "                   border-top:hidden;\n",
    "                   border-bottom:hidden;\n",
    "                   padding:10px;\n",
    "                   \">\n",
    "            The filename to be used for saving results images we generate. This uses file replacement. We can generate a dictionary object where we identify the value that will fill in the blanks. The code, <code><font color=\"Firebrick\">\"%s\"</font></code> allows a string.\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_dir = os.path.join(analysis_dir, 'images')\n",
    "div.check_dir(image_dir)\n",
    "\n",
    "site_image_dir = os.path.join(image_dir, site)\n",
    "div.check_dir(site_image_dir)\n",
    "\n",
    "data_image_dir = os.path.join(site_image_dir, dataset)\n",
    "div.check_dir(data_image_dir)\n",
    "\n",
    "image_pattern = os.path.join(data_image_dir, '%(div_metric)s_%(image_type)s_%(category)s.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#top\">Return to the top</a>\n",
    "<a id=\"download\"></a>\n",
    "## Data Download\n",
    "\n",
    "We will start our analysis using the clean, rarefied tables generated by the Preprocessing Notebook. If necessary, these files can be downloaded. The necessary files are then loaded into the notebook for analysis and processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loads the files into the notebook\n",
    "data_otu = biom.load_table(data_otu_fp)\n",
    "data_map = pd.read_csv(data_map_fp,\n",
    "                       sep=txt_delim, \n",
    "                       na_values=map_nas,\n",
    "                       index_col=False)\n",
    "data_map.index = data_map[map_index]\n",
    "del data_map[map_index]\n",
    "data_ubd = skbio.DistanceMatrix.read(data_ubd_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function definations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metadata Conversion and Massage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by creating a dataframe that will look at only the prediction and response variables. We'll use this to re-code the response variables for the regression. There are several discussion of this approach which I should probably cite at some point..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_in = data_map[con_predictors]\n",
    "data_in = data_in.join(data_map[response])\n",
    "\n",
    "for cat, (columns, f) in conversion.iteritems():\n",
    "    # Checks we should operate on this category\n",
    "    if cat not in cat_predictors:\n",
    "        continue\n",
    "    descrete = pd.DataFrame(data=np.vstack(data_map[cat].apply(f).values),\n",
    "                            index=data_map.index, columns=columns)\n",
    "    data_in = data_in.join(descrete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now, we'll remove any lines which contain undefined variables, so our regression looks only at defined data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_in = data_in.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll indentify an initial predictor and response variable. I'd like to try using `AGE` as the first variable. So, if we call our PD whole tree diversity, $y$, then we are evaluating the following relationship:\n",
    "\n",
    "$$y = \\beta_{0} + \\beta_{age}*(AGE) + \\epsilon \\tag{r1}$$\n",
    "\n",
    "We will solve for the intercept, $\\beta_{0}$, and the linear coeffecient for age, $\\beta_{age}$. Our residuals will represent the error term, $\\epsilon$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several options for permuative implementations of linear regressions. Coeffecients can be estimated using bootstrapping ... [ter Braak]. The most robust method for permutative mutlivariate linear regression is that proposed by Freedman and Lane. [Anderson, Freedman]. This method \n",
    "\n",
    "In a brief mathematical summary of the results required mostly because I don't understand well, and rephrasing things in math helps me understand..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freedman and Lane Defination of Simple Permutative Regression\n",
    "Assume there exist two vectors, $x$ and $y$ of length, $n$ where $\\bar{x}$ and $\\bar{y}$ are the respective means, and $s(x)$ and $s(y)$ are the respective standard deviations.\n",
    "\n",
    "We are testing the assumption that $x$ and $y$ are related according to equation 1.1:\n",
    "$$y = \\beta_{0} + \\beta_{1}x + \\epsilon \\tag{1.1}$$\n",
    "\n",
    "Let $r(x,y)$ be the correlation between $x$ and $y$, given by\n",
    "\n",
    "$$r(x, y) = \\frac{1}{n(s(x))(s(y))}\\sum_{m=1}^{n} (x_{m} - \\bar{x})(y_{m} - \\bar{y}) \\tag{1.2}$$\n",
    "\n",
    "Let $I_{n}$ be the index of a vector of length $n$, and let $\\pi$ be one of the $n!$ equally weighted possible permutations of $I_{n}$, such that for the $\\pi$th permuation, $i \\textrm{  } \\epsilon \\textrm{  }I_{n}$ is transformed to $i\\pi \\textrm{  }\\epsilon \\textrm{  } I_{n}$. If we apply this to one of the earlier vectors, $x$ the permutated vector, $x_{\\pi} = (x_{1\\pi}, x_{2\\pi}, ... x_{n\\pi})$.\n",
    "\n",
    "***\n",
    "**Freedman and Lane's Theorem 1**: Let $K$ be a finite, positive constant such that\n",
    "\n",
    "$$|x_{m} - \\bar{x}| < Ks(x) \\textrm{ and } |y_{m} - \\bar{y} < Ks(y)|\\tag{1.3}$$\n",
    "\n",
    "for $m \\textrm{ } \\epsilon \\textrm{ } \\mathbb{N} \\textrm{ and } m < n$.\n",
    "***\n",
    "Let \n",
    "\n",
    "$$R(\\pi) = \\sqrt{n}r(y_{\\pi}, z) \\tag{1.4}$$\n",
    "\n",
    "where as $n \\to \\infty$, R converges to a noraml distribution with mean 0 and a variance of 1. \n",
    "\n",
    "We can apply the Theorem 1 to a permuative appraoch to simple linear regression, as described in equation 1.1. In this case, $\\beta_{0}$ and $\\beta_{1}$ minimize the error sum of squares, so\n",
    "\n",
    "$$\\sum_{i = 1}^{n}(y_{i} - \\beta_{0} - \\beta_{1}x_{1})^{2} \\tag{1.5}$$\n",
    "\n",
    "The null hypothesis, that $\\beta{1} = 0$ can be tested with the statistic, $t$,\n",
    "$$t = \\frac{r\\sqrt{n - 2}}{\\sqrt{1 - r^{2}}} \\tag{1.6}$$\n",
    "where $t$ is drawn from a student's t distribution with $n - 2$ degrees of freedom.\n",
    "\n",
    "Let's assume the test statistic, $t$ in eq (1.6) is calcuate for k random permuations of y, where for the $\\pi$th permutation, the relationship\n",
    "$$y_{\\pi} = \\beta_{0\\pi} + \\beta{1\\pi}x \\tag{1.7}$$\n",
    "\n",
    "If the data is stochastic, we treat the error term in the regression model given by eq (1.1) as data, there are no outliers in the data, and $k$ is a large number, we can start to estimate a $p$ value for our null hypothesis test.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freedman and Lane Defination of Multivariate Regression\n",
    "\n",
    "Now, let's consider a case where we're testing whether $p + q$ predictors, $\\{x_{1}, x_{2}, ..., x_{p}, y_{1}, y_{2}, ... , y_{q}$ are correlated with a response variable $y$, assuming that the other variables are held constant. (Again, this is really clunky notation).\n",
    "We can express this mathematically as\n",
    "\n",
    "$$z = \\alpha_{0} + \\alpha_{1}x_{1} + \\alpha_{2}x_{2} + ... + \\alpha_{p}x_{p} + \\beta_{1}y_{1} + \\beta_{2}y_{2} + ... + \\beta_{q}y_{q} + \\epsilon \\tag{2.1}$$\n",
    "\n",
    "A multivariate regression can also be represented in linear algebra, where the response variable, $Z$ is a 1 x $n$ column vector, $X$ is an $p +  1$ x $n$ matrix where $X^{0} = 1$ and $X^{i} = x_{i}$ and Y is a $q$ x $n$ matrix and $Y^{j} = y_{j}$ ($i, j \\textrm{ } \\epsilon \\textrm{ } \\mathbb{N} \\textrm{ and } i \\leq p$ and $j \\leq q$).\n",
    "The regression coeffecients in can represented as 1 x $p + 1$ and 1 x $q$ column vectors called A and B, respectively, where $A = (\\alpha_{0}, \\alpha_{1}, \\alpha_{2}, ... \\alpha_{p})$. And, the error terms, $\\epsilon_{1}, \\epsilon_{2}, ... \\epsilon_{n}$ are collected into a 1 x $n$ column vector, E.\n",
    "\n",
    "We can represent equation (2.1) using linear algebra as \n",
    "$$Y = A \\cdot X + B \\cdot Y + E \\tag{2.2}$$\n",
    "$A$ and $B$ are chosen to minimize the sum of squares.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the $i$th coeffecient in B ($B^{i}$ or $\\beta_{i}$), we can test the following alternative hypotheses:\n",
    "<center><strong>H<sub>0</sub></strong>: $\\beta_{i} = 0$<br/>\n",
    "<strong>H<sub>1</sub></strong>: $\\beta_{i} \\neq 0$\n",
    "</center>\n",
    "\n",
    "We can use a conventional $F$ statistic to test this hypothesis, where $F(Z, X, Y)$ has $q$ degrees of freedom in the numerator and $n - p - q$ in the denomenator. We define $P$ as the level of signfigiance, or the probability of finding a value as extreme in our test $F$.\n",
    "\n",
    "If we consider on the regression with reguard to $X$, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vector of coeffecients, $B$ is a 1 x $p$ vector, where $B = (\\beta_{0}, \\beta_{1}, \\beta_{2}, ... , \\beta_{p})$. The error terms, or residuals are represented as a 1 x $n$ column vector, where $E = (\\epsilon_{1}, \\epsilon_{2}, ... \\epsilon_{n})$. This terminology allows us to write the regression equation as\n",
    "$$Y = B \\cdot X + E \\tag{2.2}$$\n",
    "\n",
    "So, given this context, we can solve for B by minimizing the sum of squares, according to a modified version of equation (1.5):\n",
    "\n",
    "$$\\sum_{i = 1}^{n}(y_{i} - B \\cdot X_{i})^{2} \\tag{2.3}$$\n",
    "\n",
    "Or, in matrix terms,\n",
    "\n",
    "$$B = (X'X)^{-1}(X'Y) \\tag{2.4}$$\n",
    "If you're interested in the deriviation of this, [resource] is recommended.\n",
    "\n",
    "We are testing the null hypothesis that $\\beta_{j} = 0$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's consider a case where we have a response varaible, column vector, $Y$ of shape 1 x $n$, and we're looking at the relationship to a matrix of $p$ predictor variables, $X$, where $X$ has dimensions $p$ x $n$, and individual predictor variables are denoted as $X^{1}, X^{2}, ... X^{p}$. The predictor value for the $i$th predictor variable and the $j$th observations is given by $X_{i,j}. Let us also assume that $X^{1} = 1.\n",
    "\n",
    "If we're not good at linear algebra, we can fit the relationship between $y$ and its predictor variables as\n",
    "\n",
    "$$y = \\beta{0} + \\beta_{1}x_{1} + \\beta_{2}x_{2} + ... + \\beta_{p}x_{p} + \\epsilon \\tag{2.1}$$\n",
    "\n",
    "In matrix space,\n",
    "$$Y = B \n",
    "\n",
    "If we were using linear algebra, we can represent the regression co-effecients, $\\{\\beta_{0}, \\beta_{1}, \\beta_{2}, ... \\beta{p}\\}$, as a $p$ x 1 row vector, $B$.\n",
    "\n",
    "We can fit the regression using the sum of least squares, so \n",
    "\n",
    "$$\\sum_{i = 1}^{n}(y_{i} -  $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def permute_linear_regression(df, response_name, predictor_name, num_iter=99, regression_params=None):\n",
    "    \"\"\"Doc string here!\"\"\"\n",
    "    if regression_params is None:\n",
    "        regression_params = {}\n",
    "    # Draws the predictor and response columns\n",
    "    y = df[response_name]\n",
    "    X = sms.add_constant(df[predictor_name])\n",
    "    \n",
    "    # Calculates the original linear regression\n",
    "    ori_model = sms.OLS(y, X, **regression_params)\n",
    "    ori_results = ori_model.fit()\n",
    "    ori_p = ori_results.pvalues\n",
    "    \n",
    "    y_index = y.index\n",
    "    \n",
    "    p_vector = np.ones(ori_p.shape[0], num_iter)\n",
    "    \n",
    "    # Calculates the permutation\n",
    "    for i in xrange(num_iter):\n",
    "        # Shuffles the labels on the response variable\n",
    "        y_shuffle = pd.Series(np.random.permutation(df[response_name].values),\n",
    "                              name=response_name, index=y_index)\n",
    "        # Performs the regression\n",
    "        shuffle_model = sms.OLS(y_shuffle, X, **regression_params)\n",
    "        shuffle_results = shuffle_model.fit()\n",
    "        p_vector[:, i] = shuffle_results.pvalues\n",
    "    \n",
    "    # Calculates the permutative p\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:     PD_whole_tree_mean   R-squared:                       0.038\n",
      "Model:                            OLS   Adj. R-squared:                  0.037\n",
      "Method:                 Least Squares   F-statistic:                     54.10\n",
      "Date:                Tue, 07 Apr 2015   Prob (F-statistic):           3.25e-13\n",
      "Time:                        16:01:34   Log-Likelihood:                -4426.6\n",
      "No. Observations:                1386   AIC:                             8857.\n",
      "Df Residuals:                    1384   BIC:                             8868.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "const         27.6559      0.438     63.106      0.000        26.796    28.516\n",
      "AGE            0.0673      0.009      7.355      0.000         0.049     0.085\n",
      "==============================================================================\n",
      "Omnibus:                        4.854   Durbin-Watson:                   2.035\n",
      "Prob(Omnibus):                  0.088   Jarque-Bera (JB):                4.741\n",
      "Skew:                          -0.136   Prob(JB):                       0.0934\n",
      "Kurtosis:                       3.090   Cond. No.                         132.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Gets predictor and responses\n",
    "y = data_in[response]\n",
    "X = sms.add_constant(data_in['AGE'])\n",
    "\n",
    "# Solves the regression\n",
    "ori_model = sms.OLS(y, X, **{})\n",
    "ori_results = model.fit()\n",
    "print res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df = data_map['BMI']\n",
    "# # Removes samples with missing data\n",
    "# df = data_map[variables].dropna()\n",
    "# model = smf.ols(formula=\"PD_whole_tree_mean ~ AGE\", data=df)\n",
    "# res = model.fit()\n",
    "# print res.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
